{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning of the Google Store Analytics Dataset\n",
    "\n",
    "## Linear Regression Models - v1\n",
    "### Version 1: Limit Input Variables, Label Encoding (instead of One Hot Encoding), No Scaling/Transforming of Data\n",
    "\n",
    "This dataset is provided by the Kaggle competition.  \n",
    "https://www.kaggle.com/c/ga-customer-revenue-prediction\n",
    "\n",
    "We performed some data engineering and datetime feature engineering to get the dataset to the state we wanted.\n",
    "\n",
    "Now we will try a variety of different models and look at their accuracy.  The models we will try:\n",
    "1. Generalized Linear Regression Models\n",
    "    1. Linear Regression (Ordinary Least Squares) Model\n",
    "    2. Linear Lasso Regression Model\n",
    "    3. Linear Ridge Regression Model\n",
    "    4. Linear Elastic Net Regression Model\n",
    "2. Decision Tree Regression - a combination of decision trees and getting continuous data output http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html  http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor\n",
    "3. Random Forest Regression??\n",
    "4. Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix\n",
    "\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Pre-processing of the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903652, 44)\n"
     ]
    }
   ],
   "source": [
    "#import the data engineered and feature engineered training dataset\n",
    "df = pd.read_pickle('data/train_v1_full_data_split.pkl')\n",
    "print(df.shape)\n",
    "# print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903652, 43)\n"
     ]
    }
   ],
   "source": [
    "### DROP COLUMNS NOT IN FINAL TEST DATA ###\n",
    "#the test dataset does not have the 'trafficSource_campaignCode' column, so drop that from our training set too\n",
    "df.drop('trafficSource_campaignCode', axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "# print(df.columns)\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE TRANSACTION REVENUE FROM NANs to 0 AND CHANGE to FLOAT TYPE (some are strings)###\n",
    "df.totals_transactionRevenue.fillna(0, inplace=True)\n",
    "df.totals_transactionRevenue = df.totals_transactionRevenue.astype(dtype=float)\n",
    "\n",
    "### CHANGE OTHER STRINGS TO INTS/FLOATS WHERE NEEDED ###\n",
    "#stick to floats rather than ints since a np.nan is a float object\n",
    "df.totals_bounces = df.totals_bounces.astype(dtype=float)\n",
    "df.totals_hits = df.totals_hits.astype(dtype=float)\n",
    "df.totals_newVisits = df.totals_newVisits.astype(dtype=float)\n",
    "df.totals_pageviews = df.totals_pageviews.astype(dtype=float)\n",
    "df.totals_visits = df.totals_visits.astype(dtype=float)\n",
    "\n",
    "### CONVERT NANs in bounces, newVisits to 0 values ###\n",
    "#the blank NAN values for these columns imply a 0 value meaning 0 newVisits or 0 bounces\n",
    "df.totals_bounces.fillna(0, inplace=True)\n",
    "df.totals_newVisits.fillna(0, inplace=True)\n",
    "# df.totals_visits.fillna(0, inplace=True) #there shouldn't be anyone with 0 visits (they've at least visited once or woulnd't be recorded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### REVENUE IS DOLLARS * 10^6, NOT EXPONENTIAL LIKE WE THOUGHT ####\n",
    "#### SINCE THE REVENUE IS SCALED UP BY A CONSTANT, NO NEED TO ADJUST FOR LIN REGRESS MODEL ####\n",
    "# ### CONVERT TRANSACTION REVENUE TO DOLLARS (instead of the e^dollars_revenue) ###\n",
    "# df['totals_transactionRevenue_dollars'] = df.totals_transactionRevenue.map(lambda x:\n",
    "#                                                                             np.log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903652, 43)\n",
      "Index(['channelGrouping', 'date', 'fullVisitorId', 'sessionId',\n",
      "       'socialEngagementType', 'visitId', 'visitNumber', 'visitStartTime',\n",
      "       'device_deviceCategory', 'device_browser', 'device_isMobile',\n",
      "       'device_operatingSystem', 'geoNetwork_subContinent',\n",
      "       'geoNetwork_region', 'geoNetwork_continent', 'geoNetwork_country',\n",
      "       'geoNetwork_city', 'geoNetwork_metro', 'geoNetwork_networkDomain',\n",
      "       'totals_bounces', 'totals_hits', 'totals_newVisits', 'totals_pageviews',\n",
      "       'totals_visits', 'totals_transactionRevenue',\n",
      "       'trafficSource_isTrueDirect', 'trafficSource_keyword',\n",
      "       'trafficSource_source', 'trafficSource_adContent',\n",
      "       'trafficSource_medium', 'trafficSource_referralPath',\n",
      "       'trafficSource_campaign', 'city_country', 'lat_lng', 'timezone',\n",
      "       'datetime_iso_utc', 'datetime_iso_local', 'year_local', 'month_local',\n",
      "       'day_local', 'yearday_local', 'weekday_local', 'hour_local'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>socialEngagementType</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>device_deviceCategory</th>\n",
       "      <th>device_browser</th>\n",
       "      <th>...</th>\n",
       "      <th>lat_lng</th>\n",
       "      <th>timezone</th>\n",
       "      <th>datetime_iso_utc</th>\n",
       "      <th>datetime_iso_local</th>\n",
       "      <th>year_local</th>\n",
       "      <th>month_local</th>\n",
       "      <th>day_local</th>\n",
       "      <th>yearday_local</th>\n",
       "      <th>weekday_local</th>\n",
       "      <th>hour_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>1131660440785968503</td>\n",
       "      <td>1131660440785968503_1472830385</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>1</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>...</td>\n",
       "      <td>(38.423734, 27.142826)</td>\n",
       "      <td>(+03, 3.0)</td>\n",
       "      <td>2016-09-02 15:33:05+00:00</td>\n",
       "      <td>2016-09-02 18:33:05+03:00</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>377306020877927890</td>\n",
       "      <td>377306020877927890_1472880147</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>1</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>...</td>\n",
       "      <td>(-25.274398, 133.775136)</td>\n",
       "      <td>(ACST, 9.5)</td>\n",
       "      <td>2016-09-03 05:22:27+00:00</td>\n",
       "      <td>2016-09-03 14:52:27+09:30</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>3895546263509774583</td>\n",
       "      <td>3895546263509774583_1472865386</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>1</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>...</td>\n",
       "      <td>(40.4167754, -3.7037902)</td>\n",
       "      <td>(CEST, 2.0)</td>\n",
       "      <td>2016-09-03 01:16:26+00:00</td>\n",
       "      <td>2016-09-03 03:16:26+02:00</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  channelGrouping      date        fullVisitorId  \\\n",
       "0  Organic Search  20160902  1131660440785968503   \n",
       "1  Organic Search  20160902   377306020877927890   \n",
       "2  Organic Search  20160902  3895546263509774583   \n",
       "\n",
       "                        sessionId  socialEngagementType     visitId  \\\n",
       "0  1131660440785968503_1472830385  Not Socially Engaged  1472830385   \n",
       "1   377306020877927890_1472880147  Not Socially Engaged  1472880147   \n",
       "2  3895546263509774583_1472865386  Not Socially Engaged  1472865386   \n",
       "\n",
       "   visitNumber  visitStartTime device_deviceCategory device_browser  \\\n",
       "0            1      1472830385               desktop         Chrome   \n",
       "1            1      1472880147               desktop        Firefox   \n",
       "2            1      1472865386               desktop         Chrome   \n",
       "\n",
       "      ...                       lat_lng     timezone  \\\n",
       "0     ...        (38.423734, 27.142826)   (+03, 3.0)   \n",
       "1     ...      (-25.274398, 133.775136)  (ACST, 9.5)   \n",
       "2     ...      (40.4167754, -3.7037902)  (CEST, 2.0)   \n",
       "\n",
       "            datetime_iso_utc         datetime_iso_local year_local  \\\n",
       "0  2016-09-02 15:33:05+00:00  2016-09-02 18:33:05+03:00     2016.0   \n",
       "1  2016-09-03 05:22:27+00:00  2016-09-03 14:52:27+09:30     2016.0   \n",
       "2  2016-09-03 01:16:26+00:00  2016-09-03 03:16:26+02:00     2016.0   \n",
       "\n",
       "  month_local day_local yearday_local weekday_local  hour_local  \n",
       "0         9.0       2.0         246.0           5.0        18.0  \n",
       "1         9.0       3.0         247.0           6.0        14.0  \n",
       "2         9.0       3.0         247.0           6.0         3.0  \n",
       "\n",
       "[3 rows x 43 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### VIEW THE DATA BEFORE LABEL/ONE HOT ENCODING ###\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>totals_bounces</th>\n",
       "      <th>totals_hits</th>\n",
       "      <th>totals_newVisits</th>\n",
       "      <th>totals_pageviews</th>\n",
       "      <th>totals_visits</th>\n",
       "      <th>totals_transactionRevenue</th>\n",
       "      <th>year_local</th>\n",
       "      <th>month_local</th>\n",
       "      <th>day_local</th>\n",
       "      <th>yearday_local</th>\n",
       "      <th>weekday_local</th>\n",
       "      <th>hour_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.036520e+05</td>\n",
       "      <td>9.036520e+05</td>\n",
       "      <td>903652.000000</td>\n",
       "      <td>9.036520e+05</td>\n",
       "      <td>903652.000000</td>\n",
       "      <td>903652.000000</td>\n",
       "      <td>903652.000000</td>\n",
       "      <td>903552.000000</td>\n",
       "      <td>903652.0</td>\n",
       "      <td>9.036520e+05</td>\n",
       "      <td>902175.000000</td>\n",
       "      <td>902175.000000</td>\n",
       "      <td>902175.000000</td>\n",
       "      <td>902175.000000</td>\n",
       "      <td>902175.000000</td>\n",
       "      <td>902175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.016589e+07</td>\n",
       "      <td>1.485007e+09</td>\n",
       "      <td>2.264898</td>\n",
       "      <td>1.485007e+09</td>\n",
       "      <td>0.498675</td>\n",
       "      <td>4.596542</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>3.849767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.704275e+06</td>\n",
       "      <td>2016.517473</td>\n",
       "      <td>6.990086</td>\n",
       "      <td>15.698499</td>\n",
       "      <td>197.611083</td>\n",
       "      <td>3.739715</td>\n",
       "      <td>13.898355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.697698e+03</td>\n",
       "      <td>9.022128e+06</td>\n",
       "      <td>9.283740</td>\n",
       "      <td>9.022128e+06</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>9.641442</td>\n",
       "      <td>0.415578</td>\n",
       "      <td>7.025277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.277869e+07</td>\n",
       "      <td>0.499695</td>\n",
       "      <td>3.486402</td>\n",
       "      <td>8.824394</td>\n",
       "      <td>106.757146</td>\n",
       "      <td>1.919636</td>\n",
       "      <td>5.806083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.016080e+07</td>\n",
       "      <td>1.470035e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.470035e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.016103e+07</td>\n",
       "      <td>1.477561e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.477561e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.017011e+07</td>\n",
       "      <td>1.483949e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.483949e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.017042e+07</td>\n",
       "      <td>1.492759e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.492759e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.017080e+07</td>\n",
       "      <td>1.501657e+09</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>1.501657e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.312950e+10</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date       visitId    visitNumber  visitStartTime  \\\n",
       "count  9.036520e+05  9.036520e+05  903652.000000    9.036520e+05   \n",
       "mean   2.016589e+07  1.485007e+09       2.264898    1.485007e+09   \n",
       "std    4.697698e+03  9.022128e+06       9.283740    9.022128e+06   \n",
       "min    2.016080e+07  1.470035e+09       1.000000    1.470035e+09   \n",
       "25%    2.016103e+07  1.477561e+09       1.000000    1.477561e+09   \n",
       "50%    2.017011e+07  1.483949e+09       1.000000    1.483949e+09   \n",
       "75%    2.017042e+07  1.492759e+09       1.000000    1.492759e+09   \n",
       "max    2.017080e+07  1.501657e+09     395.000000    1.501657e+09   \n",
       "\n",
       "       totals_bounces    totals_hits  totals_newVisits  totals_pageviews  \\\n",
       "count   903652.000000  903652.000000     903652.000000     903552.000000   \n",
       "mean         0.498675       4.596542          0.778020          3.849767   \n",
       "std          0.499999       9.641442          0.415578          7.025277   \n",
       "min          0.000000       1.000000          0.000000          1.000000   \n",
       "25%          0.000000       1.000000          1.000000          1.000000   \n",
       "50%          0.000000       2.000000          1.000000          1.000000   \n",
       "75%          1.000000       4.000000          1.000000          4.000000   \n",
       "max          1.000000     500.000000          1.000000        469.000000   \n",
       "\n",
       "       totals_visits  totals_transactionRevenue     year_local    month_local  \\\n",
       "count       903652.0               9.036520e+05  902175.000000  902175.000000   \n",
       "mean             1.0               1.704275e+06    2016.517473       6.990086   \n",
       "std              0.0               5.277869e+07       0.499695       3.486402   \n",
       "min              1.0               0.000000e+00    2016.000000       1.000000   \n",
       "25%              1.0               0.000000e+00    2016.000000       4.000000   \n",
       "50%              1.0               0.000000e+00    2017.000000       7.000000   \n",
       "75%              1.0               0.000000e+00    2017.000000      10.000000   \n",
       "max              1.0               2.312950e+10    2017.000000      12.000000   \n",
       "\n",
       "           day_local  yearday_local  weekday_local     hour_local  \n",
       "count  902175.000000  902175.000000  902175.000000  902175.000000  \n",
       "mean       15.698499     197.611083       3.739715      13.898355  \n",
       "std         8.824394     106.757146       1.919636       5.806083  \n",
       "min         1.000000       1.000000       1.000000       0.000000  \n",
       "25%         8.000000     103.000000       2.000000      10.000000  \n",
       "50%        16.000000     207.000000       4.000000      14.000000  \n",
       "75%        23.000000     297.000000       5.000000      18.000000  \n",
       "max        31.000000     366.000000       7.000000      23.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the numerical data columns for counts, mean, and min/max\n",
    "#if the standard deviation (std) is zero, that means every value is the same - may want to check that data\n",
    "#and see if need to edit it (since describe ignores NANs for instance, you may need to go back and convert the NANs to a \n",
    "#value that makes sense)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe Shape:  (903652, 43)\n",
      "\n",
      " Converting Column:  channelGrouping\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  socialEngagementType\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  device_deviceCategory\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  device_browser\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  device_isMobile\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  device_operatingSystem\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  geoNetwork_subContinent\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  geoNetwork_region\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  geoNetwork_continent\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  geoNetwork_country\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  geoNetwork_city\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  geoNetwork_metro\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  geoNetwork_networkDomain\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  trafficSource_isTrueDirect\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  trafficSource_keyword\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  trafficSource_source\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  trafficSource_adContent\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  trafficSource_medium\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  trafficSource_referralPath\n",
      "(903652, 43)\n",
      "\n",
      " Converting Column:  trafficSource_campaign\n",
      "(903652, 43)\n"
     ]
    }
   ],
   "source": [
    "### LABEL ENCODING THE CATEGORICAL VARIABLES (???SHOULD WE BE DOING ONE-HOT ENCODING INSTEAD???)###\n",
    "# label encode the categorical variables\n",
    "categorical_cols = ['channelGrouping', 'socialEngagementType', \n",
    "                   'device_deviceCategory', 'device_browser', 'device_isMobile',\n",
    "                   'device_operatingSystem', 'geoNetwork_subContinent',\n",
    "                   'geoNetwork_region', 'geoNetwork_continent', 'geoNetwork_country',\n",
    "                   'geoNetwork_city', 'geoNetwork_metro', 'geoNetwork_networkDomain',\n",
    "                   'trafficSource_isTrueDirect', 'trafficSource_keyword',\n",
    "                   'trafficSource_source', 'trafficSource_adContent',\n",
    "                   'trafficSource_medium', 'trafficSource_referralPath',\n",
    "                   'trafficSource_campaign']\n",
    "\n",
    "print('Original Dataframe Shape: ', df.shape)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print('\\n Converting Column: ', col)\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(df[col].values.astype('str')))\n",
    "    df[col] = lbl.transform(list(df[col].values.astype('str')))\n",
    "    print(df.shape)\n",
    "\n",
    "# #Kaggle competition original code\n",
    "# for col in categorical_cols:\n",
    "#     print(col)\n",
    "#     lbl = preprocessing.LabelEncoder()\n",
    "#     lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n",
    "#     train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n",
    "#     test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide what Input Data to Use for X and Split Data via train_test_split\n",
    "For initial runs of the models, try using less input data (by using the ones we think are most predictive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\scipy\\stats\\stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n",
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\scipy\\stats\\stats.py:5256: RuntimeWarning: invalid value encountered in less\n",
      "  x = np.where(x < 1.0, x, 1.0)  # if x > 1 then return 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Variable</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Absolute Value Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>totals_transactionRevenue</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>totals_pageviews</td>\n",
       "      <td>0.155590</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.155590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>totals_hits</td>\n",
       "      <td>0.154333</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.154333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visitNumber</td>\n",
       "      <td>0.051366</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.051366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>totals_newVisits</td>\n",
       "      <td>-0.041164</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.041164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>totals_bounces</td>\n",
       "      <td>-0.032206</td>\n",
       "      <td>6.106351e-206</td>\n",
       "      <td>0.032206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>trafficSource_isTrueDirect</td>\n",
       "      <td>0.030819</td>\n",
       "      <td>9.368688e-189</td>\n",
       "      <td>0.030819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>trafficSource_referralPath</td>\n",
       "      <td>-0.030432</td>\n",
       "      <td>4.310975e-184</td>\n",
       "      <td>0.030432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>geoNetwork_continent</td>\n",
       "      <td>-0.025523</td>\n",
       "      <td>4.440926e-130</td>\n",
       "      <td>0.025523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>geoNetwork_country</td>\n",
       "      <td>0.022395</td>\n",
       "      <td>1.361884e-100</td>\n",
       "      <td>0.022395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>geoNetwork_networkDomain</td>\n",
       "      <td>-0.020183</td>\n",
       "      <td>4.655084e-82</td>\n",
       "      <td>0.020183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>device_isMobile</td>\n",
       "      <td>-0.016554</td>\n",
       "      <td>8.322808e-56</td>\n",
       "      <td>0.016554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>device_deviceCategory</td>\n",
       "      <td>-0.015579</td>\n",
       "      <td>1.247157e-49</td>\n",
       "      <td>0.015579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>device_browser</td>\n",
       "      <td>-0.015119</td>\n",
       "      <td>7.592204e-47</td>\n",
       "      <td>0.015119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>trafficSource_keyword</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>2.154725e-34</td>\n",
       "      <td>0.012865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>device_operatingSystem</td>\n",
       "      <td>-0.010699</td>\n",
       "      <td>2.683086e-24</td>\n",
       "      <td>0.010699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>geoNetwork_subContinent</td>\n",
       "      <td>-0.009144</td>\n",
       "      <td>3.531718e-18</td>\n",
       "      <td>0.009144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>trafficSource_medium</td>\n",
       "      <td>-0.008569</td>\n",
       "      <td>3.764078e-16</td>\n",
       "      <td>0.008569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>trafficSource_source</td>\n",
       "      <td>-0.008393</td>\n",
       "      <td>1.477332e-15</td>\n",
       "      <td>0.008393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>weekday_local</td>\n",
       "      <td>-0.007854</td>\n",
       "      <td>8.630931e-14</td>\n",
       "      <td>0.007854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>geoNetwork_region</td>\n",
       "      <td>-0.006807</td>\n",
       "      <td>9.775028e-11</td>\n",
       "      <td>0.006807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>channelGrouping</td>\n",
       "      <td>-0.006644</td>\n",
       "      <td>2.680059e-10</td>\n",
       "      <td>0.006644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>geoNetwork_metro</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>3.117381e-05</td>\n",
       "      <td>0.004381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>trafficSource_campaign</td>\n",
       "      <td>-0.003823</td>\n",
       "      <td>2.784366e-04</td>\n",
       "      <td>0.003823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>geoNetwork_city</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>1.562743e-03</td>\n",
       "      <td>0.003327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>2.442157e-03</td>\n",
       "      <td>0.003188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>year_local</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>2.488879e-03</td>\n",
       "      <td>0.003184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>month_local</td>\n",
       "      <td>-0.002868</td>\n",
       "      <td>6.451472e-03</td>\n",
       "      <td>0.002868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>yearday_local</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>7.006445e-03</td>\n",
       "      <td>0.002839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>visitStartTime</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>9.619477e-03</td>\n",
       "      <td>0.002724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>visitId</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>9.619669e-03</td>\n",
       "      <td>0.002724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>hour_local</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>8.318176e-02</td>\n",
       "      <td>0.001824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>trafficSource_adContent</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>4.450874e-01</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>day_local</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>6.096479e-01</td>\n",
       "      <td>0.000538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>socialEngagementType</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>totals_visits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Input Variable  Correlation        p-value  \\\n",
       "22   totals_transactionRevenue     1.000000   0.000000e+00   \n",
       "20            totals_pageviews     0.155590   0.000000e+00   \n",
       "18                 totals_hits     0.154333   0.000000e+00   \n",
       "4                  visitNumber     0.051366   0.000000e+00   \n",
       "19            totals_newVisits    -0.041164   0.000000e+00   \n",
       "17              totals_bounces    -0.032206  6.106351e-206   \n",
       "23  trafficSource_isTrueDirect     0.030819  9.368688e-189   \n",
       "28  trafficSource_referralPath    -0.030432  4.310975e-184   \n",
       "12        geoNetwork_continent    -0.025523  4.440926e-130   \n",
       "13          geoNetwork_country     0.022395  1.361884e-100   \n",
       "16    geoNetwork_networkDomain    -0.020183   4.655084e-82   \n",
       "8              device_isMobile    -0.016554   8.322808e-56   \n",
       "6        device_deviceCategory    -0.015579   1.247157e-49   \n",
       "7               device_browser    -0.015119   7.592204e-47   \n",
       "24       trafficSource_keyword     0.012865   2.154725e-34   \n",
       "9       device_operatingSystem    -0.010699   2.683086e-24   \n",
       "10     geoNetwork_subContinent    -0.009144   3.531718e-18   \n",
       "27        trafficSource_medium    -0.008569   3.764078e-16   \n",
       "25        trafficSource_source    -0.008393   1.477332e-15   \n",
       "34               weekday_local    -0.007854   8.630931e-14   \n",
       "11           geoNetwork_region    -0.006807   9.775028e-11   \n",
       "0              channelGrouping    -0.006644   2.680059e-10   \n",
       "15            geoNetwork_metro     0.004381   3.117381e-05   \n",
       "29      trafficSource_campaign    -0.003823   2.784366e-04   \n",
       "14             geoNetwork_city    -0.003327   1.562743e-03   \n",
       "1                         date     0.003188   2.442157e-03   \n",
       "30                  year_local     0.003184   2.488879e-03   \n",
       "31                 month_local    -0.002868   6.451472e-03   \n",
       "33               yearday_local    -0.002839   7.006445e-03   \n",
       "5               visitStartTime     0.002724   9.619477e-03   \n",
       "3                      visitId     0.002724   9.619669e-03   \n",
       "35                  hour_local    -0.001824   8.318176e-02   \n",
       "26     trafficSource_adContent     0.000803   4.450874e-01   \n",
       "32                   day_local     0.000538   6.096479e-01   \n",
       "2         socialEngagementType          NaN   1.000000e+00   \n",
       "21               totals_visits          NaN   1.000000e+00   \n",
       "\n",
       "    Absolute Value Correlation  \n",
       "22                    1.000000  \n",
       "20                    0.155590  \n",
       "18                    0.154333  \n",
       "4                     0.051366  \n",
       "19                    0.041164  \n",
       "17                    0.032206  \n",
       "23                    0.030819  \n",
       "28                    0.030432  \n",
       "12                    0.025523  \n",
       "13                    0.022395  \n",
       "16                    0.020183  \n",
       "8                     0.016554  \n",
       "6                     0.015579  \n",
       "7                     0.015119  \n",
       "24                    0.012865  \n",
       "9                     0.010699  \n",
       "10                    0.009144  \n",
       "27                    0.008569  \n",
       "25                    0.008393  \n",
       "34                    0.007854  \n",
       "11                    0.006807  \n",
       "0                     0.006644  \n",
       "15                    0.004381  \n",
       "29                    0.003823  \n",
       "14                    0.003327  \n",
       "1                     0.003188  \n",
       "30                    0.003184  \n",
       "31                    0.002868  \n",
       "33                    0.002839  \n",
       "5                     0.002724  \n",
       "3                     0.002724  \n",
       "35                    0.001824  \n",
       "26                    0.000803  \n",
       "32                    0.000538  \n",
       "2                          NaN  \n",
       "21                         NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CALCULATE CORRELATION OF EACH POSSIBLE INPUT vs. REVENUE VALUE - TO HELP DECISION MAKING OF WHICH INPUTS TO INCLUDE###\n",
    "correlation_summary_list = []\n",
    "\n",
    "for col in df.columns:\n",
    "    #can only run correlations on columns that have numerical values (either dtype of float or int)\n",
    "    #in particular some columns have dtype of 'O', which stands for python object, which in this case means the dtypes are mixed\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        \n",
    "        #having NANs in the dataset for correlations breaks the correlation calculation\n",
    "        #so only keep the good_rows that don't have nans for either series being used in the correlation calculation\n",
    "        #and then np.compress(good_rows, series) just reduces the series to the array with only the good_rows to run the correlation\n",
    "        good_rows = ~np.logical_or(np.isnan(df[col]), np.isnan(df.totals_transactionRevenue))\n",
    "\n",
    "        #pearsonr function calculates the Pearson correlation coefficient and the p-value for as a tuple\n",
    "        correl_pvalue = pearsonr(np.compress(good_rows, df[col]), np.compress(good_rows, df.totals_transactionRevenue))\n",
    "\n",
    "        #create new tuple that also has the column name (which is the input variable) and the correl coef and p-value\n",
    "        variable_correl_pvalue = (col,) + correl_pvalue\n",
    "\n",
    "        #add the correl and pvalue tuple to the list of all correlation summaries\n",
    "        correlation_summary_list.append(variable_correl_pvalue)\n",
    "\n",
    "        \n",
    "#create a dataframe of the correlation summary (for ease of readibility/manipulation)    \n",
    "correlation_summary_df = pd.DataFrame(correlation_summary_list, columns=['Input Variable', 'Correlation', 'p-value'])\n",
    "#create a new column of absolute value of correlations so can easily sort both positive and negative correlations together\n",
    "correlation_summary_df['Absolute Value Correlation'] = correlation_summary_df.Correlation.map(lambda correl: abs(correl))\n",
    "#sort the dataframe by absolute value correlation high to low\n",
    "correlation_summary_df.sort_values('Absolute Value Correlation', ascending=False, inplace=True)\n",
    "\n",
    "#print output\n",
    "correlation_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of all of our variables being used for the model (before dropping nans):  (903652, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of all of our variables being used for the model (after dropping nans):  (902077, 15)\n",
      "\n",
      "Shape of X input variables is:  (902077, 14) \n",
      "Shape of y output variable is:  (902077, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "### ASSIGN X and y DATA for VARIALBES WE WANT TO USE###\n",
    "\n",
    "# for X data use the initial correlation values and variables that we think are most important to narrow things down\n",
    "# (remember, that the correlation values are just linear correlation values, so this doesn't capture variables\n",
    "# that do have a large influence but might be nonlinear, however, for linear regression models at the least, that\n",
    "# seems like a good metric to start with as the linear models won't be able to capture nonlinear affects well anyways)\n",
    "\n",
    "#INITIAL RUN DECISIONS: as we can see from the initial Pearson correlations, no variables even fall within the range of what\n",
    "#we would consider even low correlations traditionally, so it is doubtful that linear regression models will work well,\n",
    "#but we'll try it out - take the top 10 variables and also include weekday_local, month_local, yearday_local, and hour_local\n",
    "#since those are features we specifically added to make our features unique\n",
    "\n",
    "\n",
    "\n",
    "#start with a reduced dataframe that includes all x input variables and the y output variable\n",
    "#do this so that can clean the dataframe by dropping all rows tha have any nans\n",
    "df_model = df[['totals_pageviews', 'totals_hits', 'visitNumber', 'totals_newVisits', 'totals_bounces',\n",
    "              'trafficSource_isTrueDirect', 'trafficSource_referralPath',\n",
    "              'geoNetwork_continent', 'geoNetwork_country', 'geoNetwork_networkDomain',\n",
    "              'weekday_local', 'month_local', 'yearday_local', 'hour_local',\n",
    "              'totals_transactionRevenue']]\n",
    "print('\\nShape of all of our variables being used for the model (before dropping nans): ', df_model.shape)\n",
    "\n",
    "#for linear regression drop NANs as they can't be interpreted in the regression model - check to make\n",
    "#sure it isn't reducing size of data too much before proceeding\n",
    "df_model.dropna(axis='index', how=\"any\", inplace=True)\n",
    "print('\\nShape of all of our variables being used for the model (after dropping nans): ', df_model.shape)\n",
    "\n",
    "#add a column to the df_model data of a simple classifier of \"revenue\" or \"no_revenue\" - will use this data point for:\n",
    "#  1) evaluating the accuracy of the model later (for example, if our errors are low and R2 high, but it is incorrectly\n",
    "#     assigning any revenue value to customers with no revenue, that'd be a problem)\n",
    "#  2) in the train_test_split model we will use the stratify command to get equal train-test percentages for both revenue\n",
    "#     and no revenue outcomes - I think this will be important since only about 1.3% of all rows actually resulted in \n",
    "#     revenue and not completely sure how randomly selecting will have equal test-train distributions without defining it\n",
    "#     (this may be unnecessary, but better safe than sorry)\n",
    "df_model['revenue_label'] = df_model.totals_transactionRevenue.map(lambda revenue_amount: \n",
    "                                                        'revenue' if revenue_amount > 0 else 'no_revenue')\n",
    "\n",
    "\n",
    "#split out the data we are using for modeling to X and y values\n",
    "X_model = df_model[['totals_pageviews', 'totals_hits', 'visitNumber', 'totals_newVisits', 'totals_bounces',\n",
    "              'trafficSource_isTrueDirect', 'trafficSource_referralPath',\n",
    "              'geoNetwork_continent', 'geoNetwork_country', 'geoNetwork_networkDomain',\n",
    "              'weekday_local', 'month_local', 'yearday_local', 'hour_local']]\n",
    "\n",
    "#need to reshape the y_model data so that the array is of shape (902077, 1) which is (902077 rows, 1 column)\n",
    "#rather than (90277,) which is (902077 rows, 0 column)\n",
    "y_model = df_model['totals_transactionRevenue'].values.reshape(-1, 1)\n",
    "\n",
    "#put stratify criteria of revenue_yes_no into its own array, make sure to reshape this as well\n",
    "stratify_criteria_model = df_model['revenue_label'].values.reshape(-1, 1)\n",
    "\n",
    "print('\\nShape of X input variables is: ', X_model.shape, '\\nShape of y output variable is: ', y_model.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ???NEED TO SCALE/TRANSFORM THE DATA???? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Shapes of the train-test data splits.\n",
      "\n",
      "X_model_train:  (676557, 14)\n",
      "X_model_test:  (225520, 14)\n",
      "y_model_train:  (676557, 1)\n",
      "y_model_test:  (225520, 1)\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Check that the train-test data split worked along stratify criteria.\n",
      "\n",
      "The df_model data percentages of revenue and no_revenue are:\n",
      "no_revenue    0.987242\n",
      "revenue       0.012758\n",
      "Name: revenue_label, dtype: float64\n",
      "\n",
      "The percentage of model_train data that has revenue is:  0.01275871803853925\n",
      "\n",
      "The percentage of model_test data that has revenue is:  0.012757183398368215\n"
     ]
    }
   ],
   "source": [
    "##### TRAIN-TEST-SPLIT #####\n",
    "\n",
    "### SPLIT THE MODEL DATA ###\n",
    "#split the model data (which is all of the Kaggle Training data) into the model's train/test subsets\n",
    "#(have to do this since Kaggle competition has its own test data, but those actual values are not provided, so can't\n",
    "#actually use that to test our models, just end up comparing our predictions on that test data with their actuals)\n",
    "#use a 75-25 split to start with train-test\n",
    "#also make sure to add stratify_criteria to make sure it is doing a 75-25 split on both website visits that led to \n",
    "#actual sales/revenue and those that did not\n",
    "X_model_train, X_model_test, y_model_train, y_model_test = train_test_split(X_model, y_model,\n",
    "                                                                            test_size=0.25,\n",
    "                                                                            stratify=stratify_criteria_model)\n",
    "#print sizes of the train/test data splits\n",
    "print('Check Shapes of the train-test data splits.\\n')\n",
    "print('X_model_train: ', X_model_train.shape)\n",
    "print('X_model_test: ', X_model_test.shape)\n",
    "print('y_model_train: ', y_model_train.shape)\n",
    "print('y_model_test: ', y_model_test.shape)\n",
    "\n",
    "\n",
    "### VERIFTY THE STRATEFIY COMMAND WORKED ###\n",
    "print('\\n--------------------------------------------------------------------')\n",
    "print('Check that the train-test data split worked along stratify criteria.\\n')\n",
    "\n",
    "# FIRST PRINT OUT TOTAL DF_MODEL PERCENTAGE OF DATA THAT HAS REVENUE #\n",
    "print('The df_model data percentages of revenue and no_revenue are:')\n",
    "#since this data from the df_model is in a series, we can just use pandas value counts\n",
    "print(df_model['revenue_label'].value_counts(normalize=True))\n",
    "\n",
    "# THEN CHECK THE TRAIN DATA #\n",
    "#the train data is now an array, so can't use value_counts, have to use np commands\n",
    "#filter the data to be only y_values that had revenue (rev>0) by using the np.where command\n",
    "#it creates a mask of booleans that you can use to filter your array based on whatever criteria you give it\n",
    "#take the length of this filtered array to figure out how many y_values actually had revenue\n",
    "y_model_train_revenue_count = len(y_model_train[np.where(y_model_train > 0)])\n",
    "#calculate the percentage of the y_values that have revenue by taking the revenue count/total count in that dataset \n",
    "#note: this percentage should equal the overall percentage of your data that has revenue if the stratify command is working properly\n",
    "y_model_train_revenue_percent = y_model_train_revenue_count/y_model_train.shape[0]\n",
    "print('\\nThe percentage of model_train data that has revenue is: ', y_model_train_revenue_percent)\n",
    "\n",
    "# THEN VERIFY THE STRATFIY COMMAND WORKED - SECOND CHECK THE TEST DATA #\n",
    "#the test data is now an array, so can't use value_counts, have to use np commands\n",
    "#filter the data to be only y_values that had revenue (rev>0) by using the np.where command\n",
    "#it creates a mask of booleans that you can use to filter your array based on whatever criteria you give it\n",
    "#take the length of this filtered array to figure out how many y_values actually had revenue\n",
    "y_model_test_revenue_count = len(y_model_test[np.where(y_model_test > 0)])\n",
    "#calculate the percentage of the y_values that have revenue by taking the revenue count/total count in that dataset \n",
    "#note: this percentage should equal the overall percentage of your data that has revenue if the stratify command is working properly\n",
    "y_model_test_revenue_percent = y_model_test_revenue_count/y_model_test.shape[0]\n",
    "print('\\nThe percentage of model_test data that has revenue is: ', y_model_test_revenue_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Models v1\n",
    "##### Without Scaling/Transforming, Limited Input Variables, Use of Label Encoding (instead of one-hot-encoding), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to define whether the outcome is revenue (when revenue_amt is greater than 0), \n",
    "#no_revenue (when revenue_amt is 0), and neg_revenue (when revenue_amt is less than 0)\n",
    "def revenue_norevenue_negrevenue(revenue_amt):\n",
    "    if revenue_amt > 0:\n",
    "        return 'revenue'\n",
    "    elif revenue_amt == 0:\n",
    "        return 'no_revenue'\n",
    "    elif revenue_amt < 0:\n",
    "        return 'neg_revenue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE A FUNCTION THAT EVALUATES THE REVENUE OR NO_REVENUE ACCURACY ###\n",
    "#an important part of this model is to make sure that only people that actually performed a final transaction are \n",
    "#getting a revenue prediction\n",
    "#so calculate the percentages of each outcome in a confusion matrix using sklearn.metrics.confusion_matrix:\n",
    "# --True Positive: Revenue_actual & Revenue_predicted\n",
    "# --True Negative: No_Revenue_actual & No_Revenue_predicted\n",
    "# --False Negative: Revenue_actual & No_Revenue_predicted\n",
    "# --False Positive: No_Revenue_actual & Revenue_predicted\n",
    "\n",
    "#inputs of y_revenue_true, y_revenue_predicted are the actual revenue amount arrays,\n",
    "#we will convert to labels\n",
    "def evaluate_revenue_confusion_matrix(y_revenue_true, y_revenue_predicted):\n",
    "    df_revenue_eval = pd.DataFrame(data={'revenue_actual': y_revenue_true.reshape(-1),\n",
    "                       'revenue_prediction': y_revenue_predicted.reshape(-1)})\n",
    "    \n",
    "    df_revenue_eval['revenue_label_actual'] = df_revenue_eval.revenue_actual.map(revenue_norevenue_negrevenue)\n",
    "    \n",
    "    df_revenue_eval['revenue_label_prediction'] = df_revenue_eval.revenue_prediction.map(revenue_norevenue_negrevenue)\n",
    "    \n",
    "    print('Confusion Matrix of revenue/no_revenue/neg_revenue: \\n')\n",
    "    #use scikit learns confusion matrix (the diagonal indicates true hits, outside of that is the false hits)\n",
    "    print(confusion_matrix(df_revenue_eval.revenue_label_actual,\n",
    "                 df_revenue_eval.revenue_label_prediction,\n",
    "                 labels=['revenue', 'no_revenue', 'neg_revenue']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Linear Regression (Ordinary Least Squares) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSTANTIATE, FIT, and PREDICT THE MODEL ###\n",
    "\n",
    "#instantiate the LinearRegression model\n",
    "lin_reg_model = LinearRegression()\n",
    "\n",
    "#fit the training X, y data using the model\n",
    "lin_reg_model.fit(X_model_train, y_model_train)\n",
    "\n",
    "#make predictions using the model\n",
    "y_lin_reg_test_predictions = lin_reg_model.predict(X_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1722713059096698.2 \n",
      "R-squared: 0.04348373509403003 \n",
      "Correlation: 0.2085275403730405\n"
     ]
    }
   ],
   "source": [
    "### EVALUATE THE MODEL USING MSE, R2, CORREL ###\n",
    "\n",
    "#MSE function syntax: mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=â€™uniform_averageâ€™)\n",
    "MSE_lin_reg = mean_squared_error(y_model_test, y_lin_reg_test_predictions)\n",
    "\n",
    "#R2 function syntax: r2_score(y_true, y_pred, sample_weight=None, multioutput=â€™uniform_averageâ€™)\n",
    "r2_lin_reg = r2_score(y_model_test, y_lin_reg_test_predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {} \\nR-squared: {} \\nCorrelation: {}\".format(MSE_lin_reg, r2_lin_reg, np.sqrt(r2_lin_reg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of revenue/no_revenue/neg_revenue: \n",
      "\n",
      "[[  2876      0      1]\n",
      " [ 83598      0 139045]\n",
      " [     0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_revenue_confusion_matrix(y_model_test, y_lin_reg_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Linear Lasso Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "### INSTANTIATE, FIT, and PREDICT THE MODEL ###\n",
    "\n",
    "#instantiate the LinearRegression model\n",
    "lasso_model = Lasso(alpha=.01)\n",
    "\n",
    "#fit the training X, y data using the model\n",
    "lasso_model.fit(X_model_train, y_model_train)\n",
    "\n",
    "#make predictions using the model\n",
    "y_lasso_test_predictions = lasso_model.predict(X_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1722713062244528.8 \n",
      "R-squared: 0.04348373334623401 \n",
      "Correlation: 0.20852753618223663\n"
     ]
    }
   ],
   "source": [
    "### EVALUATE THE MODEL USING MSE, R2, CORREL ###\n",
    "\n",
    "#MSE function syntax: mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=â€™uniform_averageâ€™)\n",
    "MSE_lasso = mean_squared_error(y_model_test, y_lasso_test_predictions)\n",
    "\n",
    "#R2 function syntax: r2_score(y_true, y_pred, sample_weight=None, multioutput=â€™uniform_averageâ€™)\n",
    "r2_lasso = r2_score(y_model_test, y_lasso_test_predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {} \\nR-squared: {} \\nCorrelation: {}\".format(MSE_lasso, r2_lasso, np.sqrt(r2_lasso)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of revenue/no_revenue/neg_revenue: \n",
      "\n",
      "[[  2876      0      1]\n",
      " [ 83596      0 139047]\n",
      " [     0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_revenue_confusion_matrix(y_model_test, y_lasso_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Linear Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSTANTIATE, FIT, and PREDICT THE MODEL ###\n",
    "\n",
    "#instantiate the LinearRegression model\n",
    "ridge_model = Ridge(alpha=.01)\n",
    "\n",
    "#fit the training X, y data using the model\n",
    "ridge_model.fit(X_model_train, y_model_train)\n",
    "\n",
    "#make predictions using the model\n",
    "y_ridge_test_predictions = ridge_model.predict(X_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1722713059109972.0 \n",
      "R-squared: 0.043483735086659925 \n",
      "Correlation: 0.20852754035536872\n"
     ]
    }
   ],
   "source": [
    "### EVALUATE THE MODEL USING MSE, R2, CORREL ###\n",
    "\n",
    "#MSE function syntax: mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=â€™uniform_averageâ€™)\n",
    "MSE_ridge = mean_squared_error(y_model_test, y_ridge_test_predictions)\n",
    "\n",
    "#R2 function syntax: r2_score(y_true, y_pred, sample_weight=None, multioutput=â€™uniform_averageâ€™)\n",
    "r2_ridge = r2_score(y_model_test, y_ridge_test_predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {} \\nR-squared: {} \\nCorrelation: {}\".format(MSE_ridge, r2_ridge, np.sqrt(r2_ridge)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of revenue/no_revenue/neg_revenue: \n",
      "\n",
      "[[  2876      0      1]\n",
      " [ 83598      0 139045]\n",
      " [     0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_revenue_confusion_matrix(y_model_test, y_ridge_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Linear Elastic Net Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "### INSTANTIATE, FIT, and PREDICT THE MODEL ###\n",
    "\n",
    "#instantiate the LinearRegression model\n",
    "elastic_net_model = ElasticNet(alpha=.01)\n",
    "\n",
    "#fit the training X, y data using the model\n",
    "elastic_net_model.fit(X_model_train, y_model_train)\n",
    "\n",
    "#make predictions using the model\n",
    "y_elastic_net_test_predictions = elastic_net_model.predict(X_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1722719863189738.5 \n",
      "R-squared: 0.04347995720099862 \n",
      "Correlation: 0.20851848167728113\n"
     ]
    }
   ],
   "source": [
    "### EVALUATE THE MODEL USING MSE, R2, CORREL ###\n",
    "\n",
    "#MSE function syntax: mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=â€™uniform_averageâ€™)\n",
    "MSE_elastic_net = mean_squared_error(y_model_test, y_elastic_net_test_predictions)\n",
    "\n",
    "#R2 function syntax: r2_score(y_true, y_pred, sample_weight=None, multioutput=â€™uniform_averageâ€™)\n",
    "r2_elastic_net = r2_score(y_model_test, y_elastic_net_test_predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {} \\nR-squared: {} \\nCorrelation: {}\".format(MSE_elastic_net, r2_elastic_net, np.sqrt(r2_elastic_net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of revenue/no_revenue/neg_revenue: \n",
      "\n",
      "[[  2876      0      1]\n",
      " [ 83089      0 139554]\n",
      " [     0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_revenue_confusion_matrix(y_model_test, y_elastic_net_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
