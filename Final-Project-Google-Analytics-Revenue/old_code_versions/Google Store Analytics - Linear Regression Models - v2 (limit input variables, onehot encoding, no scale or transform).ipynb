{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning of the Google Store Analytics Dataset\n",
    "\n",
    "## Linear Regression Models - v2\n",
    "### Version 2: Limit Input Variables, One Hot Encoding, No Scaling/Transforming of Data\n",
    "\n",
    "This dataset is provided by the Kaggle competition.  \n",
    "https://www.kaggle.com/c/ga-customer-revenue-prediction\n",
    "\n",
    "We performed some data engineering and datetime feature engineering to get the dataset to the state we wanted.\n",
    "\n",
    "Now we will try a variety of different models and look at their accuracy.  The models we will try:\n",
    "1. Generalized Linear Regression Models\n",
    "    1. Linear Regression (Ordinary Least Squares) Model\n",
    "    2. Linear Lasso Regression Model\n",
    "    3. Linear Ridge Regression Model\n",
    "    4. Linear Elastic Net Regression Model\n",
    "2. Decision Tree Regression - a combination of decision trees and getting continuous data output http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html  http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor\n",
    "3. Random Forest Regression??\n",
    "4. Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael_suomi/anaconda3/lib/python3.5/site-packages/sklearn/utils/fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix\n",
    "\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Pre-processing of the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('data/train_v1_full_data_split.pkl', 'rb') as fp:\n",
    "#     df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903652, 44)\n"
     ]
    }
   ],
   "source": [
    "#import the data engineered and feature engineered training dataset\n",
    "df = pd.read_pickle('/home/michael_suomi/Final-Project-Google-Merch-Store/data/train_v1_full_data_split.pkl')\n",
    "print(df.shape)\n",
    "# print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903652, 43)\n"
     ]
    }
   ],
   "source": [
    "### DROP COLUMNS NOT IN FINAL TEST DATA ###\n",
    "#the test dataset does not have the 'trafficSource_campaignCode' column, so drop that from our training set too\n",
    "df.drop('trafficSource_campaignCode', axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "# print(df.columns)\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CHANGE TRANSACTION REVENUE FROM NANs to 0 AND CHANGE to FLOAT TYPE (some are strings)###\n",
    "df.totals_transactionRevenue.fillna(0, inplace=True)\n",
    "df.totals_transactionRevenue = df.totals_transactionRevenue.astype(dtype=float)\n",
    "\n",
    "### CHANGE OTHER STRINGS TO INTS/FLOATS WHERE NEEDED ###\n",
    "#stick to floats rather than ints since a np.nan is a float object\n",
    "df.totals_bounces = df.totals_bounces.astype(dtype=float)\n",
    "df.totals_hits = df.totals_hits.astype(dtype=float)\n",
    "df.totals_newVisits = df.totals_newVisits.astype(dtype=float)\n",
    "df.totals_pageviews = df.totals_pageviews.astype(dtype=float)\n",
    "df.totals_visits = df.totals_visits.astype(dtype=float)\n",
    "\n",
    "### CONVERT NANs in bounces, newVisits to 0 values ###\n",
    "#the blank NAN values for these columns imply a 0 value meaning 0 newVisits or 0 bounces\n",
    "df.totals_bounces.fillna(0, inplace=True)\n",
    "df.totals_newVisits.fillna(0, inplace=True)\n",
    "# df.totals_visits.fillna(0, inplace=True) #there shouldn't be anyone with 0 visits (they've at least visited once or woulnd't be recorded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### REVENUE IS DOLLARS * 10^6, NOT EXPONENTIAL LIKE WE THOUGHT ####\n",
    "#### SINCE THE REVENUE IS SCALED UP BY A CONSTANT, NO NEED TO ADJUST FOR LIN REGRESS MODEL ####\n",
    "# ### CONVERT TRANSACTION REVENUE TO DOLLARS (instead of the e^dollars_revenue) ###\n",
    "# df['totals_transactionRevenue_dollars'] = df.totals_transactionRevenue.map(lambda x:\n",
    "#                                                                             np.log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903652, 43)\n",
      "Index(['channelGrouping', 'date', 'fullVisitorId', 'sessionId',\n",
      "       'socialEngagementType', 'visitId', 'visitNumber', 'visitStartTime',\n",
      "       'device_deviceCategory', 'device_browser', 'device_isMobile',\n",
      "       'device_operatingSystem', 'geoNetwork_subContinent',\n",
      "       'geoNetwork_region', 'geoNetwork_continent', 'geoNetwork_country',\n",
      "       'geoNetwork_city', 'geoNetwork_metro', 'geoNetwork_networkDomain',\n",
      "       'totals_bounces', 'totals_hits', 'totals_newVisits', 'totals_pageviews',\n",
      "       'totals_visits', 'totals_transactionRevenue',\n",
      "       'trafficSource_isTrueDirect', 'trafficSource_keyword',\n",
      "       'trafficSource_source', 'trafficSource_adContent',\n",
      "       'trafficSource_medium', 'trafficSource_referralPath',\n",
      "       'trafficSource_campaign', 'city_country', 'lat_lng', 'timezone',\n",
      "       'datetime_iso_utc', 'datetime_iso_local', 'year_local', 'month_local',\n",
      "       'day_local', 'yearday_local', 'weekday_local', 'hour_local'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelGrouping</th>\n",
       "      <th>date</th>\n",
       "      <th>fullVisitorId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>socialEngagementType</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>device_deviceCategory</th>\n",
       "      <th>device_browser</th>\n",
       "      <th>...</th>\n",
       "      <th>lat_lng</th>\n",
       "      <th>timezone</th>\n",
       "      <th>datetime_iso_utc</th>\n",
       "      <th>datetime_iso_local</th>\n",
       "      <th>year_local</th>\n",
       "      <th>month_local</th>\n",
       "      <th>day_local</th>\n",
       "      <th>yearday_local</th>\n",
       "      <th>weekday_local</th>\n",
       "      <th>hour_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>1131660440785968503</td>\n",
       "      <td>1131660440785968503_1472830385</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>1</td>\n",
       "      <td>1472830385</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>...</td>\n",
       "      <td>(38.423734, 27.142826)</td>\n",
       "      <td>(+03, 3.0)</td>\n",
       "      <td>2016-09-02 15:33:05+00:00</td>\n",
       "      <td>2016-09-02 18:33:05+03:00</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>377306020877927890</td>\n",
       "      <td>377306020877927890_1472880147</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>1</td>\n",
       "      <td>1472880147</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>...</td>\n",
       "      <td>(-25.274398, 133.775136)</td>\n",
       "      <td>(ACST, 9.5)</td>\n",
       "      <td>2016-09-03 05:22:27+00:00</td>\n",
       "      <td>2016-09-03 14:52:27+09:30</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organic Search</td>\n",
       "      <td>20160902</td>\n",
       "      <td>3895546263509774583</td>\n",
       "      <td>3895546263509774583_1472865386</td>\n",
       "      <td>Not Socially Engaged</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>1</td>\n",
       "      <td>1472865386</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>...</td>\n",
       "      <td>(40.4167754, -3.7037902)</td>\n",
       "      <td>(CEST, 2.0)</td>\n",
       "      <td>2016-09-03 01:16:26+00:00</td>\n",
       "      <td>2016-09-03 03:16:26+02:00</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  channelGrouping      date        fullVisitorId  \\\n",
       "0  Organic Search  20160902  1131660440785968503   \n",
       "1  Organic Search  20160902   377306020877927890   \n",
       "2  Organic Search  20160902  3895546263509774583   \n",
       "\n",
       "                        sessionId  socialEngagementType     visitId  \\\n",
       "0  1131660440785968503_1472830385  Not Socially Engaged  1472830385   \n",
       "1   377306020877927890_1472880147  Not Socially Engaged  1472880147   \n",
       "2  3895546263509774583_1472865386  Not Socially Engaged  1472865386   \n",
       "\n",
       "   visitNumber  visitStartTime device_deviceCategory device_browser  \\\n",
       "0            1      1472830385               desktop         Chrome   \n",
       "1            1      1472880147               desktop        Firefox   \n",
       "2            1      1472865386               desktop         Chrome   \n",
       "\n",
       "      ...                       lat_lng     timezone  \\\n",
       "0     ...        (38.423734, 27.142826)   (+03, 3.0)   \n",
       "1     ...      (-25.274398, 133.775136)  (ACST, 9.5)   \n",
       "2     ...      (40.4167754, -3.7037902)  (CEST, 2.0)   \n",
       "\n",
       "            datetime_iso_utc         datetime_iso_local year_local  \\\n",
       "0  2016-09-02 15:33:05+00:00  2016-09-02 18:33:05+03:00     2016.0   \n",
       "1  2016-09-03 05:22:27+00:00  2016-09-03 14:52:27+09:30     2016.0   \n",
       "2  2016-09-03 01:16:26+00:00  2016-09-03 03:16:26+02:00     2016.0   \n",
       "\n",
       "  month_local day_local yearday_local weekday_local  hour_local  \n",
       "0         9.0       2.0         246.0           5.0        18.0  \n",
       "1         9.0       3.0         247.0           6.0        14.0  \n",
       "2         9.0       3.0         247.0           6.0         3.0  \n",
       "\n",
       "[3 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### VIEW THE DATA BEFORE LABEL/ONE HOT ENCODING ###\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>visitId</th>\n",
       "      <th>visitNumber</th>\n",
       "      <th>visitStartTime</th>\n",
       "      <th>totals_bounces</th>\n",
       "      <th>totals_hits</th>\n",
       "      <th>totals_newVisits</th>\n",
       "      <th>totals_pageviews</th>\n",
       "      <th>totals_visits</th>\n",
       "      <th>totals_transactionRevenue</th>\n",
       "      <th>year_local</th>\n",
       "      <th>month_local</th>\n",
       "      <th>day_local</th>\n",
       "      <th>yearday_local</th>\n",
       "      <th>weekday_local</th>\n",
       "      <th>hour_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.036520e+05</td>\n",
       "      <td>9.036520e+05</td>\n",
       "      <td>903652.000000</td>\n",
       "      <td>9.036520e+05</td>\n",
       "      <td>903652.000000</td>\n",
       "      <td>903652.000000</td>\n",
       "      <td>903652.000000</td>\n",
       "      <td>903552.000000</td>\n",
       "      <td>903652.0</td>\n",
       "      <td>9.036520e+05</td>\n",
       "      <td>902175.000000</td>\n",
       "      <td>902175.000000</td>\n",
       "      <td>902175.000000</td>\n",
       "      <td>902175.000000</td>\n",
       "      <td>902175.000000</td>\n",
       "      <td>902175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.016589e+07</td>\n",
       "      <td>1.485007e+09</td>\n",
       "      <td>2.264898</td>\n",
       "      <td>1.485007e+09</td>\n",
       "      <td>0.498675</td>\n",
       "      <td>4.596542</td>\n",
       "      <td>0.778020</td>\n",
       "      <td>3.849767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.704275e+06</td>\n",
       "      <td>2016.517473</td>\n",
       "      <td>6.990086</td>\n",
       "      <td>15.698499</td>\n",
       "      <td>197.611083</td>\n",
       "      <td>3.739715</td>\n",
       "      <td>13.898355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.697698e+03</td>\n",
       "      <td>9.022128e+06</td>\n",
       "      <td>9.283740</td>\n",
       "      <td>9.022128e+06</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>9.641442</td>\n",
       "      <td>0.415578</td>\n",
       "      <td>7.025277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.277869e+07</td>\n",
       "      <td>0.499695</td>\n",
       "      <td>3.486402</td>\n",
       "      <td>8.824394</td>\n",
       "      <td>106.757146</td>\n",
       "      <td>1.919636</td>\n",
       "      <td>5.806083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.016080e+07</td>\n",
       "      <td>1.470035e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.470035e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.016103e+07</td>\n",
       "      <td>1.477561e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.477561e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.017011e+07</td>\n",
       "      <td>1.483949e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.483949e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.017042e+07</td>\n",
       "      <td>1.492759e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.492759e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.017080e+07</td>\n",
       "      <td>1.501657e+09</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>1.501657e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.312950e+10</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date       visitId    visitNumber  visitStartTime  \\\n",
       "count  9.036520e+05  9.036520e+05  903652.000000    9.036520e+05   \n",
       "mean   2.016589e+07  1.485007e+09       2.264898    1.485007e+09   \n",
       "std    4.697698e+03  9.022128e+06       9.283740    9.022128e+06   \n",
       "min    2.016080e+07  1.470035e+09       1.000000    1.470035e+09   \n",
       "25%    2.016103e+07  1.477561e+09       1.000000    1.477561e+09   \n",
       "50%    2.017011e+07  1.483949e+09       1.000000    1.483949e+09   \n",
       "75%    2.017042e+07  1.492759e+09       1.000000    1.492759e+09   \n",
       "max    2.017080e+07  1.501657e+09     395.000000    1.501657e+09   \n",
       "\n",
       "       totals_bounces    totals_hits  totals_newVisits  totals_pageviews  \\\n",
       "count   903652.000000  903652.000000     903652.000000     903552.000000   \n",
       "mean         0.498675       4.596542          0.778020          3.849767   \n",
       "std          0.499999       9.641442          0.415578          7.025277   \n",
       "min          0.000000       1.000000          0.000000          1.000000   \n",
       "25%          0.000000       1.000000          1.000000          1.000000   \n",
       "50%          0.000000       2.000000          1.000000          1.000000   \n",
       "75%          1.000000       4.000000          1.000000          4.000000   \n",
       "max          1.000000     500.000000          1.000000        469.000000   \n",
       "\n",
       "       totals_visits  totals_transactionRevenue     year_local    month_local  \\\n",
       "count       903652.0               9.036520e+05  902175.000000  902175.000000   \n",
       "mean             1.0               1.704275e+06    2016.517473       6.990086   \n",
       "std              0.0               5.277869e+07       0.499695       3.486402   \n",
       "min              1.0               0.000000e+00    2016.000000       1.000000   \n",
       "25%              1.0               0.000000e+00    2016.000000       4.000000   \n",
       "50%              1.0               0.000000e+00    2017.000000       7.000000   \n",
       "75%              1.0               0.000000e+00    2017.000000      10.000000   \n",
       "max              1.0               2.312950e+10    2017.000000      12.000000   \n",
       "\n",
       "           day_local  yearday_local  weekday_local     hour_local  \n",
       "count  902175.000000  902175.000000  902175.000000  902175.000000  \n",
       "mean       15.698499     197.611083       3.739715      13.898355  \n",
       "std         8.824394     106.757146       1.919636       5.806083  \n",
       "min         1.000000       1.000000       1.000000       0.000000  \n",
       "25%         8.000000     103.000000       2.000000      10.000000  \n",
       "50%        16.000000     207.000000       4.000000      14.000000  \n",
       "75%        23.000000     297.000000       5.000000      18.000000  \n",
       "max        31.000000     366.000000       7.000000      23.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the numerical data columns for counts, mean, and min/max\n",
    "#if the standard deviation (std) is zero, that means every value is the same - may want to check that data\n",
    "#and see if need to edit it (since describe ignores NANs for instance, you may need to go back and convert the NANs to a \n",
    "#value that makes sense)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe Shape:  (903652, 43) \n",
      "Will be storing one hot encoded categories in new dataframe\n",
      "\n",
      " Converting Column:  trafficSource_isTrueDirect\n",
      "(903652, 2)\n",
      "\n",
      " Converting Column:  trafficSource_source\n",
      "(903652, 383)\n",
      "\n",
      " Converting Column:  geoNetwork_continent\n",
      "(903652, 390)\n",
      "\n",
      " Converting Column:  geoNetwork_country\n",
      "(903652, 613)\n"
     ]
    }
   ],
   "source": [
    "### ONE HOT ENCODING THE CATEGORICAL VARIABLES ###\n",
    "# one hot encode the categorical variables\n",
    "\n",
    "## got a memory error when one hot encoded all these columns - limit it based on what we think is most important features we'll use ##\n",
    "# categorical_cols = ['channelGrouping', 'socialEngagementType', \n",
    "#                    'device_deviceCategory', 'device_browser', 'device_isMobile',\n",
    "#                    'device_operatingSystem', 'geoNetwork_subContinent',\n",
    "#                    'geoNetwork_region', 'geoNetwork_continent', 'geoNetwork_country',\n",
    "#                    'geoNetwork_city', 'geoNetwork_metro', 'geoNetwork_networkDomain',\n",
    "#                    'trafficSource_isTrueDirect', 'trafficSource_keyword',\n",
    "#                    'trafficSource_source', 'trafficSource_adContent',\n",
    "#                    'trafficSource_medium', 'trafficSource_referralPath',\n",
    "#                    'trafficSource_campaign']\n",
    "\n",
    "#based on previous analyses, start with these categorical variables that seem more important\n",
    "#trafficSource_referralPath is way too many options/slight nuances (gives the actual web address someone was referred from\n",
    "#and created like 1500 columns, which broke the memory error again); instead use trafficSource_source which narrows it down\n",
    "#to the domain of the source web address\n",
    "#'geoNetwork_networkDomain' also appears to be blowing up the size so take it out as well\n",
    "categorical_cols = ['trafficSource_isTrueDirect', 'trafficSource_source',\n",
    "#                     'trafficSource_keyword', #tons of dimensions and not good predictor\n",
    "                    'geoNetwork_continent', 'geoNetwork_country'\n",
    "#                     'geoNetwork_city'\n",
    "                   ]\n",
    "                    #???do the weekdays/months/hours need one hot encoding too? because while they are numbers they are kind of like categories\n",
    "                    #'weekday_local', 'month_local', 'yearday_local', 'hour_local']\n",
    "\n",
    "#for reference print size of orginal df\n",
    "print('Original Dataframe Shape: ', df.shape, '\\nWill be storing one hot encoded categories in new dataframe')\n",
    "\n",
    "#store these one hot encoded categories in a new dataframe (should make selecting columsn easier later)\n",
    "df_categorical_onehot = pd.DataFrame()\n",
    "\n",
    "#convert one at a time in a for loop just to keep track of how much each column expands the size of our dataframe\n",
    "for col in categorical_cols:\n",
    "    print('\\n Converting Column: ', col)\n",
    "    \n",
    "    #use pd.get_dummies to one hot encoding - keep all columns for now (rather than dropping one, so can keep track of all\n",
    "    #separate coefficients/correlations)\n",
    "    #dummy_na=True adds a column to indicate NaNs, which I think is important for this dataset given how many NaNs we have\n",
    "    #in many columns\n",
    "    col_categorical_onehot = pd.get_dummies(df[col], columns=[col], prefix=col, dummy_na=True)\n",
    "    \n",
    "    df_categorical_onehot = pd.concat([df_categorical_onehot, col_categorical_onehot], axis=1)\n",
    "    \n",
    "    #check size of the modified df\n",
    "    print(df_categorical_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trafficSource_isTrueDirect_true</th>\n",
       "      <th>trafficSource_isTrueDirect_nan</th>\n",
       "      <th>trafficSource_source_(direct)</th>\n",
       "      <th>trafficSource_source_(not set)</th>\n",
       "      <th>trafficSource_source_0.muppet1.frontend.gws.muppet-exp.ij-q.borg.google.com:14634</th>\n",
       "      <th>trafficSource_source_0.shared.bow.cat2.ads-bow.lf.borg.google.com:9817</th>\n",
       "      <th>trafficSource_source_0.shared.bow.cat2.ads-bow.lf.borg.google.com:9824</th>\n",
       "      <th>trafficSource_source_0.shared.bow.cat2.ads-bow.lf.borg.google.com:9857</th>\n",
       "      <th>trafficSource_source_0.shared.bow.cat2.ads-bow.lf.borg.google.com:9860</th>\n",
       "      <th>trafficSource_source_0.shared.bow.cat2.ads-bow.lf.borg.google.com:9879</th>\n",
       "      <th>...</th>\n",
       "      <th>geoNetwork_country_Uruguay</th>\n",
       "      <th>geoNetwork_country_Uzbekistan</th>\n",
       "      <th>geoNetwork_country_Vanuatu</th>\n",
       "      <th>geoNetwork_country_Venezuela</th>\n",
       "      <th>geoNetwork_country_Vietnam</th>\n",
       "      <th>geoNetwork_country_Yemen</th>\n",
       "      <th>geoNetwork_country_Zambia</th>\n",
       "      <th>geoNetwork_country_Zimbabwe</th>\n",
       "      <th>geoNetwork_country_Åland Islands</th>\n",
       "      <th>geoNetwork_country_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 613 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trafficSource_isTrueDirect_true  trafficSource_isTrueDirect_nan  \\\n",
       "0                                0                               1   \n",
       "1                                0                               1   \n",
       "2                                0                               1   \n",
       "3                                0                               1   \n",
       "4                                1                               0   \n",
       "\n",
       "   trafficSource_source_(direct)  trafficSource_source_(not set)  \\\n",
       "0                              0                               0   \n",
       "1                              0                               0   \n",
       "2                              0                               0   \n",
       "3                              0                               0   \n",
       "4                              0                               0   \n",
       "\n",
       "   trafficSource_source_0.muppet1.frontend.gws.muppet-exp.ij-q.borg.google.com:14634  \\\n",
       "0                                                  0                                   \n",
       "1                                                  0                                   \n",
       "2                                                  0                                   \n",
       "3                                                  0                                   \n",
       "4                                                  0                                   \n",
       "\n",
       "   trafficSource_source_0.shared.bow.cat2.ads-bow.lf.borg.google.com:9817  \\\n",
       "0                                                  0                        \n",
       "1                                                  0                        \n",
       "2                                                  0                        \n",
       "3                                                  0                        \n",
       "4                                                  0                        \n",
       "\n",
       "   trafficSource_source_0.shared.bow.cat2.ads-bow.lf.borg.google.com:9824  \\\n",
       "0                                                  0                        \n",
       "1                                                  0                        \n",
       "2                                                  0                        \n",
       "3                                                  0                        \n",
       "4                                                  0                        \n",
       "\n",
       "   trafficSource_source_0.shared.bow.cat2.ads-bow.lf.borg.google.com:9857  \\\n",
       "0                                                  0                        \n",
       "1                                                  0                        \n",
       "2                                                  0                        \n",
       "3                                                  0                        \n",
       "4                                                  0                        \n",
       "\n",
       "   trafficSource_source_0.shared.bow.cat2.ads-bow.lf.borg.google.com:9860  \\\n",
       "0                                                  0                        \n",
       "1                                                  0                        \n",
       "2                                                  0                        \n",
       "3                                                  0                        \n",
       "4                                                  0                        \n",
       "\n",
       "   trafficSource_source_0.shared.bow.cat2.ads-bow.lf.borg.google.com:9879  \\\n",
       "0                                                  0                        \n",
       "1                                                  0                        \n",
       "2                                                  0                        \n",
       "3                                                  0                        \n",
       "4                                                  0                        \n",
       "\n",
       "            ...            geoNetwork_country_Uruguay  \\\n",
       "0           ...                                     0   \n",
       "1           ...                                     0   \n",
       "2           ...                                     0   \n",
       "3           ...                                     0   \n",
       "4           ...                                     0   \n",
       "\n",
       "   geoNetwork_country_Uzbekistan  geoNetwork_country_Vanuatu  \\\n",
       "0                              0                           0   \n",
       "1                              0                           0   \n",
       "2                              0                           0   \n",
       "3                              0                           0   \n",
       "4                              0                           0   \n",
       "\n",
       "   geoNetwork_country_Venezuela  geoNetwork_country_Vietnam  \\\n",
       "0                             0                           0   \n",
       "1                             0                           0   \n",
       "2                             0                           0   \n",
       "3                             0                           0   \n",
       "4                             0                           0   \n",
       "\n",
       "   geoNetwork_country_Yemen  geoNetwork_country_Zambia  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "\n",
       "   geoNetwork_country_Zimbabwe  geoNetwork_country_Åland Islands  \\\n",
       "0                            0                                 0   \n",
       "1                            0                                 0   \n",
       "2                            0                                 0   \n",
       "3                            0                                 0   \n",
       "4                            0                                 0   \n",
       "\n",
       "   geoNetwork_country_nan  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 613 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categorical_onehot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide what Input Data to Use for X and Split Data via train_test_split\n",
    "For initial runs of the models, try using less input data (by using the ones we think are most predictive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael_suomi/anaconda3/lib/python3.5/site-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Variable</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Absolute Value Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>totals_transactionRevenue</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>totals_pageviews</td>\n",
       "      <td>0.155590</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.155590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>totals_hits</td>\n",
       "      <td>0.154333</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.154333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visitNumber</td>\n",
       "      <td>0.051366</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.051366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>totals_newVisits</td>\n",
       "      <td>-0.041164</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.041164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>totals_bounces</td>\n",
       "      <td>-0.032206</td>\n",
       "      <td>6.106351e-206</td>\n",
       "      <td>0.032206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>weekday_local</td>\n",
       "      <td>-0.007854</td>\n",
       "      <td>8.630931e-14</td>\n",
       "      <td>0.007854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>2.442157e-03</td>\n",
       "      <td>0.003188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>year_local</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>2.488879e-03</td>\n",
       "      <td>0.003184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>month_local</td>\n",
       "      <td>-0.002868</td>\n",
       "      <td>6.451472e-03</td>\n",
       "      <td>0.002868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>yearday_local</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>7.006445e-03</td>\n",
       "      <td>0.002839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>visitStartTime</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>9.619477e-03</td>\n",
       "      <td>0.002724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>visitId</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>9.619669e-03</td>\n",
       "      <td>0.002724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hour_local</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>8.318176e-02</td>\n",
       "      <td>0.001824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>day_local</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>6.096479e-01</td>\n",
       "      <td>0.000538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>totals_visits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Input Variable  Correlation        p-value  \\\n",
       "9   totals_transactionRevenue     1.000000   0.000000e+00   \n",
       "7            totals_pageviews     0.155590   0.000000e+00   \n",
       "5                 totals_hits     0.154333   0.000000e+00   \n",
       "2                 visitNumber     0.051366   0.000000e+00   \n",
       "6            totals_newVisits    -0.041164   0.000000e+00   \n",
       "4              totals_bounces    -0.032206  6.106351e-206   \n",
       "14              weekday_local    -0.007854   8.630931e-14   \n",
       "0                        date     0.003188   2.442157e-03   \n",
       "10                 year_local     0.003184   2.488879e-03   \n",
       "11                month_local    -0.002868   6.451472e-03   \n",
       "13              yearday_local    -0.002839   7.006445e-03   \n",
       "3              visitStartTime     0.002724   9.619477e-03   \n",
       "1                     visitId     0.002724   9.619669e-03   \n",
       "15                 hour_local    -0.001824   8.318176e-02   \n",
       "12                  day_local     0.000538   6.096479e-01   \n",
       "8               totals_visits          NaN   1.000000e+00   \n",
       "\n",
       "    Absolute Value Correlation  \n",
       "9                     1.000000  \n",
       "7                     0.155590  \n",
       "5                     0.154333  \n",
       "2                     0.051366  \n",
       "6                     0.041164  \n",
       "4                     0.032206  \n",
       "14                    0.007854  \n",
       "0                     0.003188  \n",
       "10                    0.003184  \n",
       "11                    0.002868  \n",
       "13                    0.002839  \n",
       "3                     0.002724  \n",
       "1                     0.002724  \n",
       "15                    0.001824  \n",
       "12                    0.000538  \n",
       "8                          NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CALCULATE CORRELATION OF EACH POSSIBLE INPUT vs. REVENUE VALUE ---ORIGINAL DF--- TO HELP DECISION MAKING OF WHICH INPUTS TO INCLUDE###\n",
    "correlation_summary_list = []\n",
    "\n",
    "for col in df.columns:\n",
    "    #can only run correlations on columns that have numerical values (either dtype of float or int)\n",
    "    #in particular some columns have dtype of 'O', which stands for python object, which in this case means the dtypes are mixed\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        \n",
    "        #having NANs in the dataset for correlations breaks the correlation calculation\n",
    "        #so only keep the good_rows that don't have nans for either series being used in the correlation calculation\n",
    "        #and then np.compress(good_rows, series) just reduces the series to the array with only the good_rows to run the correlation\n",
    "        good_rows = ~np.logical_or(np.isnan(df[col]), np.isnan(df.totals_transactionRevenue))\n",
    "\n",
    "        #pearsonr function calculates the Pearson correlation coefficient and the p-value for as a tuple\n",
    "        correl_pvalue = pearsonr(np.compress(good_rows, df[col]), np.compress(good_rows, df.totals_transactionRevenue))\n",
    "\n",
    "        #create new tuple that also has the column name (which is the input variable) and the correl coef and p-value\n",
    "        variable_correl_pvalue = (col,) + correl_pvalue\n",
    "\n",
    "        #add the correl and pvalue tuple to the list of all correlation summaries\n",
    "        correlation_summary_list.append(variable_correl_pvalue)\n",
    "\n",
    "        \n",
    "#create a dataframe of the correlation summary (for ease of readibility/manipulation)    \n",
    "correlation_summary_df = pd.DataFrame(correlation_summary_list, columns=['Input Variable', 'Correlation', 'p-value'])\n",
    "#create a new column of absolute value of correlations so can easily sort both positive and negative correlations together\n",
    "correlation_summary_df['Absolute Value Correlation'] = correlation_summary_df.Correlation.map(lambda correl: abs(correl))\n",
    "#sort the dataframe by absolute value correlation high to low\n",
    "correlation_summary_df.sort_values('Absolute Value Correlation', ascending=False, inplace=True)\n",
    "\n",
    "#print output\n",
    "correlation_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael_suomi/anaconda3/lib/python3.5/site-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Variable</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Absolute Value Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>trafficSource_source_mall.googleplex.com</td>\n",
       "      <td>0.040157</td>\n",
       "      <td>4.368331e-319</td>\n",
       "      <td>0.040157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>geoNetwork_country_United States</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>7.048387e-250</td>\n",
       "      <td>0.035505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>geoNetwork_continent_Americas</td>\n",
       "      <td>0.030910</td>\n",
       "      <td>7.276022e-190</td>\n",
       "      <td>0.030910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trafficSource_isTrueDirect_true</td>\n",
       "      <td>0.030819</td>\n",
       "      <td>9.368688e-189</td>\n",
       "      <td>0.030819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trafficSource_isTrueDirect_nan</td>\n",
       "      <td>-0.030819</td>\n",
       "      <td>9.368688e-189</td>\n",
       "      <td>0.030819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>trafficSource_source_youtube.com</td>\n",
       "      <td>-0.017895</td>\n",
       "      <td>6.633589e-65</td>\n",
       "      <td>0.017895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>trafficSource_source_dfa</td>\n",
       "      <td>0.017829</td>\n",
       "      <td>1.940800e-64</td>\n",
       "      <td>0.017829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>geoNetwork_continent_Asia</td>\n",
       "      <td>-0.017676</td>\n",
       "      <td>2.277786e-63</td>\n",
       "      <td>0.017676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>geoNetwork_continent_Europe</td>\n",
       "      <td>-0.016780</td>\n",
       "      <td>2.738178e-57</td>\n",
       "      <td>0.016780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>trafficSource_source_google</td>\n",
       "      <td>-0.013256</td>\n",
       "      <td>2.068431e-36</td>\n",
       "      <td>0.013256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trafficSource_source_(direct)</td>\n",
       "      <td>0.010977</td>\n",
       "      <td>1.722450e-25</td>\n",
       "      <td>0.010977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>trafficSource_source_mail.google.com</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>3.950347e-25</td>\n",
       "      <td>0.010893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>geoNetwork_country_India</td>\n",
       "      <td>-0.007846</td>\n",
       "      <td>8.777993e-14</td>\n",
       "      <td>0.007846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>geoNetwork_country_United Kingdom</td>\n",
       "      <td>-0.006531</td>\n",
       "      <td>5.348392e-10</td>\n",
       "      <td>0.006531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>geoNetwork_country_Vietnam</td>\n",
       "      <td>-0.005402</td>\n",
       "      <td>2.823909e-07</td>\n",
       "      <td>0.005402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>geoNetwork_country_Turkey</td>\n",
       "      <td>-0.004908</td>\n",
       "      <td>3.077118e-06</td>\n",
       "      <td>0.004908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>geoNetwork_country_Thailand</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>4.876232e-06</td>\n",
       "      <td>0.004807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>geoNetwork_country_Germany</td>\n",
       "      <td>-0.004777</td>\n",
       "      <td>5.592985e-06</td>\n",
       "      <td>0.004777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>geoNetwork_country_Brazil</td>\n",
       "      <td>-0.004739</td>\n",
       "      <td>6.639291e-06</td>\n",
       "      <td>0.004739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>trafficSource_source_analytics.google.com</td>\n",
       "      <td>-0.004359</td>\n",
       "      <td>3.417811e-05</td>\n",
       "      <td>0.004359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>trafficSource_source_Partners</td>\n",
       "      <td>-0.004298</td>\n",
       "      <td>4.396726e-05</td>\n",
       "      <td>0.004298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>geoNetwork_country_France</td>\n",
       "      <td>-0.004241</td>\n",
       "      <td>5.546142e-05</td>\n",
       "      <td>0.004241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>geoNetwork_country_Venezuela</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>6.279467e-05</td>\n",
       "      <td>0.004210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>trafficSource_source_dealspotr.com</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>7.767059e-05</td>\n",
       "      <td>0.004157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>geoNetwork_continent_Oceania</td>\n",
       "      <td>-0.003909</td>\n",
       "      <td>2.023153e-04</td>\n",
       "      <td>0.003909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>geoNetwork_country_Japan</td>\n",
       "      <td>-0.003859</td>\n",
       "      <td>2.440234e-04</td>\n",
       "      <td>0.003859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>geoNetwork_country_Russia</td>\n",
       "      <td>-0.003675</td>\n",
       "      <td>4.774661e-04</td>\n",
       "      <td>0.003675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>geoNetwork_country_Mexico</td>\n",
       "      <td>-0.003657</td>\n",
       "      <td>5.078525e-04</td>\n",
       "      <td>0.003657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>geoNetwork_country_Spain</td>\n",
       "      <td>-0.003620</td>\n",
       "      <td>5.789645e-04</td>\n",
       "      <td>0.003620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>geoNetwork_country_Netherlands</td>\n",
       "      <td>-0.003610</td>\n",
       "      <td>5.998155e-04</td>\n",
       "      <td>0.003610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>trafficSource_source_brewmaster.corp.google.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>geoNetwork_country_São Tomé &amp; Príncipe</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>trafficSource_source_0.shared.bow.cat2.ads-bow...</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>trafficSource_source_mmisciagna2.sbo.corp.goog...</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>trafficSource_source_takeout.google.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>trafficSource_source_biztools.corp.google.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>trafficSource_source_us.wow.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>trafficSource_source_mx.search.yahoo.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>trafficSource_source_id.search.yahoo.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>trafficSource_source_newsstand.google.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>trafficSource_source_0.shared.bow.cat2.ads-bow...</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>trafficSource_source_google.com.pe</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>trafficSource_source_espanol.search.yahoo.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>trafficSource_source_0.shared.bow.cat2.ads-bow...</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>trafficSource_source_0.shared.bow.cat2.ads-bow...</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>trafficSource_source_0.shared.bow.cat2.ads-bow...</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>trafficSource_source_yahoo.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>trafficSource_source_google.com.ar</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>trafficSource_source_it.pinterest.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>geoNetwork_country_Eritrea</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>trafficSource_source_0.shared.bow.cat2.ads-bow...</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>trafficSource_source_s7-eu4.ixquick.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>trafficSource_source_meetup.com</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>trafficSource_source_0.shared.bow.cat2.ads-bow...</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>9.742400e-01</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>geoNetwork_country_Puerto Rico</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>9.750235e-01</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>trafficSource_source_trainup.withgoogle.com</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>9.751553e-01</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>trafficSource_source_search.xfinity.com</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>9.836520e-01</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>trafficSource_source_nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>geoNetwork_continent_nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>geoNetwork_country_nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Input Variable  Correlation  \\\n",
       "269           trafficSource_source_mall.googleplex.com     0.040157   \n",
       "602                   geoNetwork_country_United States     0.035505   \n",
       "385                      geoNetwork_continent_Americas     0.030910   \n",
       "0                      trafficSource_isTrueDirect_true     0.030819   \n",
       "1                       trafficSource_isTrueDirect_nan    -0.030819   \n",
       "380                   trafficSource_source_youtube.com    -0.017895   \n",
       "122                           trafficSource_source_dfa     0.017829   \n",
       "386                          geoNetwork_continent_Asia    -0.017676   \n",
       "387                        geoNetwork_continent_Europe    -0.016780   \n",
       "151                        trafficSource_source_google    -0.013256   \n",
       "2                        trafficSource_source_(direct)     0.010977   \n",
       "265               trafficSource_source_mail.google.com     0.010893   \n",
       "483                           geoNetwork_country_India    -0.007846   \n",
       "601                  geoNetwork_country_United Kingdom    -0.006531   \n",
       "607                         geoNetwork_country_Vietnam    -0.005402   \n",
       "594                          geoNetwork_country_Turkey    -0.004908   \n",
       "589                        geoNetwork_country_Thailand    -0.004807   \n",
       "465                         geoNetwork_country_Germany    -0.004777   \n",
       "418                          geoNetwork_country_Brazil    -0.004739   \n",
       "69           trafficSource_source_analytics.google.com    -0.004359   \n",
       "56                       trafficSource_source_Partners    -0.004298   \n",
       "459                          geoNetwork_country_France    -0.004241   \n",
       "606                       geoNetwork_country_Venezuela     0.004210   \n",
       "119                 trafficSource_source_dealspotr.com     0.004157   \n",
       "388                       geoNetwork_continent_Oceania    -0.003909   \n",
       "492                           geoNetwork_country_Japan    -0.003859   \n",
       "554                          geoNetwork_country_Russia    -0.003675   \n",
       "522                          geoNetwork_country_Mexico    -0.003657   \n",
       "571                           geoNetwork_country_Spain    -0.003620   \n",
       "532                     geoNetwork_country_Netherlands    -0.003610   \n",
       "..                                                 ...          ...   \n",
       "92     trafficSource_source_brewmaster.corp.google.com    -0.000034   \n",
       "585             geoNetwork_country_São Tomé & Príncipe    -0.000034   \n",
       "24   trafficSource_source_0.shared.bow.cat2.ads-bow...    -0.000034   \n",
       "276  trafficSource_source_mmisciagna2.sbo.corp.goog...    -0.000034   \n",
       "347            trafficSource_source_takeout.google.com    -0.000034   \n",
       "85       trafficSource_source_biztools.corp.google.com    -0.000034   \n",
       "360                    trafficSource_source_us.wow.com    -0.000034   \n",
       "282           trafficSource_source_mx.search.yahoo.com    -0.000034   \n",
       "215           trafficSource_source_id.search.yahoo.com    -0.000034   \n",
       "289          trafficSource_source_newsstand.google.com    -0.000034   \n",
       "48   trafficSource_source_0.shared.bow.cat2.ads-bow...    -0.000034   \n",
       "175                 trafficSource_source_google.com.pe    -0.000034   \n",
       "131      trafficSource_source_espanol.search.yahoo.com    -0.000034   \n",
       "54   trafficSource_source_0.shared.bow.cat2.ads-bow...    -0.000034   \n",
       "42   trafficSource_source_0.shared.bow.cat2.ads-bow...    -0.000034   \n",
       "23   trafficSource_source_0.shared.bow.cat2.ads-bow...    -0.000034   \n",
       "378                     trafficSource_source_yahoo.com    -0.000034   \n",
       "168                 trafficSource_source_google.com.ar    -0.000034   \n",
       "234              trafficSource_source_it.pinterest.com    -0.000034   \n",
       "453                         geoNetwork_country_Eritrea    -0.000034   \n",
       "19   trafficSource_source_0.shared.bow.cat2.ads-bow...    -0.000034   \n",
       "319            trafficSource_source_s7-eu4.ixquick.com    -0.000034   \n",
       "272                    trafficSource_source_meetup.com    -0.000034   \n",
       "15   trafficSource_source_0.shared.bow.cat2.ads-bow...    -0.000034   \n",
       "551                     geoNetwork_country_Puerto Rico    -0.000033   \n",
       "350        trafficSource_source_trainup.withgoogle.com    -0.000033   \n",
       "331            trafficSource_source_search.xfinity.com    -0.000022   \n",
       "382                           trafficSource_source_nan          NaN   \n",
       "389                           geoNetwork_continent_nan          NaN   \n",
       "612                             geoNetwork_country_nan          NaN   \n",
       "\n",
       "           p-value  Absolute Value Correlation  \n",
       "269  4.368331e-319                    0.040157  \n",
       "602  7.048387e-250                    0.035505  \n",
       "385  7.276022e-190                    0.030910  \n",
       "0    9.368688e-189                    0.030819  \n",
       "1    9.368688e-189                    0.030819  \n",
       "380   6.633589e-65                    0.017895  \n",
       "122   1.940800e-64                    0.017829  \n",
       "386   2.277786e-63                    0.017676  \n",
       "387   2.738178e-57                    0.016780  \n",
       "151   2.068431e-36                    0.013256  \n",
       "2     1.722450e-25                    0.010977  \n",
       "265   3.950347e-25                    0.010893  \n",
       "483   8.777993e-14                    0.007846  \n",
       "601   5.348392e-10                    0.006531  \n",
       "607   2.823909e-07                    0.005402  \n",
       "594   3.077118e-06                    0.004908  \n",
       "589   4.876232e-06                    0.004807  \n",
       "465   5.592985e-06                    0.004777  \n",
       "418   6.639291e-06                    0.004739  \n",
       "69    3.417811e-05                    0.004359  \n",
       "56    4.396726e-05                    0.004298  \n",
       "459   5.546142e-05                    0.004241  \n",
       "606   6.279467e-05                    0.004210  \n",
       "119   7.767059e-05                    0.004157  \n",
       "388   2.023153e-04                    0.003909  \n",
       "492   2.440234e-04                    0.003859  \n",
       "554   4.774661e-04                    0.003675  \n",
       "522   5.078525e-04                    0.003657  \n",
       "571   5.789645e-04                    0.003620  \n",
       "532   5.998155e-04                    0.003610  \n",
       "..             ...                         ...  \n",
       "92    9.742400e-01                    0.000034  \n",
       "585   9.742400e-01                    0.000034  \n",
       "24    9.742400e-01                    0.000034  \n",
       "276   9.742400e-01                    0.000034  \n",
       "347   9.742400e-01                    0.000034  \n",
       "85    9.742400e-01                    0.000034  \n",
       "360   9.742400e-01                    0.000034  \n",
       "282   9.742400e-01                    0.000034  \n",
       "215   9.742400e-01                    0.000034  \n",
       "289   9.742400e-01                    0.000034  \n",
       "48    9.742400e-01                    0.000034  \n",
       "175   9.742400e-01                    0.000034  \n",
       "131   9.742400e-01                    0.000034  \n",
       "54    9.742400e-01                    0.000034  \n",
       "42    9.742400e-01                    0.000034  \n",
       "23    9.742400e-01                    0.000034  \n",
       "378   9.742400e-01                    0.000034  \n",
       "168   9.742400e-01                    0.000034  \n",
       "234   9.742400e-01                    0.000034  \n",
       "453   9.742400e-01                    0.000034  \n",
       "19    9.742400e-01                    0.000034  \n",
       "319   9.742400e-01                    0.000034  \n",
       "272   9.742400e-01                    0.000034  \n",
       "15    9.742400e-01                    0.000034  \n",
       "551   9.750235e-01                    0.000033  \n",
       "350   9.751553e-01                    0.000033  \n",
       "331   9.836520e-01                    0.000022  \n",
       "382   1.000000e+00                         NaN  \n",
       "389   1.000000e+00                         NaN  \n",
       "612   1.000000e+00                         NaN  \n",
       "\n",
       "[613 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CALCULATE CORRELATION OF EACH POSSIBLE INPUT vs. REVENUE VALUE ---ONEHOT CATEGORICAL DF---  TO HELP DECISION MAKING OF WHICH INPUTS TO INCLUDE###\n",
    "categ_correlation_summary_list = []\n",
    "\n",
    "for col in df_categorical_onehot.columns:\n",
    "    #onehotencoded categorical columns are all 0/1 ints, so can calculate all correlations\n",
    "        \n",
    "    #having NANs in the dataset for correlations breaks the correlation calculation\n",
    "    #so only keep the good_rows that don't have nans for either series being used in the correlation calculation\n",
    "    #and then np.compress(good_rows, series) just reduces the series to the array with only the good_rows to run the correlation\n",
    "    good_rows = ~np.logical_or(np.isnan(df_categorical_onehot[col]), np.isnan(df.totals_transactionRevenue))\n",
    "\n",
    "    #pearsonr function calculates the Pearson correlation coefficient and the p-value for as a tuple\n",
    "    correl_pvalue = pearsonr(np.compress(good_rows, df_categorical_onehot[col]), np.compress(good_rows, df.totals_transactionRevenue))\n",
    "\n",
    "    #create new tuple that also has the column name (which is the input variable) and the correl coef and p-value\n",
    "    variable_correl_pvalue = (col,) + correl_pvalue\n",
    "\n",
    "    #add the correl and pvalue tuple to the list of all correlation summaries\n",
    "    categ_correlation_summary_list.append(variable_correl_pvalue)\n",
    "\n",
    "        \n",
    "#create a dataframe of the correlation summary (for ease of readibility/manipulation)    \n",
    "categ_correlation_summary_df = pd.DataFrame(categ_correlation_summary_list, columns=['Input Variable', 'Correlation', 'p-value'])\n",
    "#create a new column of absolute value of correlations so can easily sort both positive and negative correlations together\n",
    "categ_correlation_summary_df['Absolute Value Correlation'] = categ_correlation_summary_df.Correlation.map(lambda correl: abs(correl))\n",
    "#sort the dataframe by absolute value correlation high to low\n",
    "categ_correlation_summary_df.sort_values('Absolute Value Correlation', ascending=False, inplace=True)\n",
    "\n",
    "#print output\n",
    "categ_correlation_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of all of our variables being used for the model (before dropping nans):  (903652, 623)\n",
      "\n",
      "Shape of all of our variables being used for the model (after dropping nans):  (902077, 623)\n",
      "\n",
      "Shape of X input variables is:  (902077, 622) \n",
      "Shape of y output variable is:  (902077, 1)\n"
     ]
    }
   ],
   "source": [
    "### ASSIGN X and y DATA for VARIALBES WE WANT TO USE###\n",
    "\n",
    "# for X data use the initial correlation values and variables that we think are most important to narrow things down\n",
    "# (remember, that the correlation values are just linear correlation values, so this doesn't capture variables\n",
    "# that do have a large influence but might be nonlinear, however, for linear regression models at the least, that\n",
    "# seems like a good metric to start with as the linear models won't be able to capture nonlinear affects well anyways)\n",
    "\n",
    "#INITIAL RUN DECISIONS: as we can see from the initial Pearson correlations, no variables even fall within the range of what\n",
    "#we would consider even low correlations traditionally, so it is doubtful that linear regression models will work well,\n",
    "#but we'll try it out - take roughly top 10 variables, use all one hot encoded columns and also include\n",
    "#weekday_local, month_local, yearday_local, and hour_local since those are features we specifically added to\n",
    "#make our features unique\n",
    "\n",
    "\n",
    "#create list of the chosen numerical column names based on above\n",
    "numerical_columns_x_model = ['totals_pageviews', 'totals_hits', 'visitNumber', 'totals_newVisits', 'totals_bounces',\n",
    "                             'weekday_local', 'month_local', 'yearday_local', 'hour_local']\n",
    "                           \n",
    "#create the model dataframe that includes chosen x input variables (from numerical and onehot encoded) and y output variable\n",
    "#do this so that can clean the dataframe by dropping all rows that have any nans\n",
    "df_model = pd.concat([df[numerical_columns_x_model], #the chosen numerical column x-values\n",
    "                      df_categorical_onehot, #the chosen categorical onehot encoded x-values\n",
    "                      df['totals_transactionRevenue']], #the y-value of revenue\n",
    "                      axis=1)\n",
    "print('\\nShape of all of our variables being used for the model (before dropping nans): ', df_model.shape)\n",
    "\n",
    "\n",
    "#for linear regression drop NANs as they can't be interpreted in the regression model - check to make\n",
    "#sure it isn't reducing size of data too much before proceeding\n",
    "df_model.dropna(axis='index', how='any', inplace=True)\n",
    "print('\\nShape of all of our variables being used for the model (after dropping nans): ', df_model.shape)\n",
    "\n",
    "#add a column to the df_model data of a simple classifier of \"revenue\" or \"no_revenue\" - will use this data point for:\n",
    "#     in the train_test_split model we will use the stratify command to get equal train-test percentages for both revenue\n",
    "#     and no revenue outcomes - I think this will be important since only about 1.3% of all rows actually resulted in \n",
    "#     revenue and not completely sure how randomly selecting will have equal test-train distributions without defining it\n",
    "#     (this may be unnecessary, but better safe than sorry)\n",
    "df_model['revenue_label'] = df_model.totals_transactionRevenue.map(lambda revenue_amount: \n",
    "                                                        'revenue' if revenue_amount > 0 else 'no_revenue')\n",
    "\n",
    "\n",
    "#split out the data we are using for modeling to X and y values\n",
    "columns_X_model = [col for col in list(df_model.columns) if col not in ['totals_transactionRevenue', 'revenue_label']]\n",
    "X_model = df_model[columns_X_model]\n",
    "\n",
    "#need to reshape the y_model data so that the array is of shape (902077, 1) which is (902077 rows, 1 column)\n",
    "#rather than (90277,) which is (902077 rows, 0 column)\n",
    "y_model = df_model['totals_transactionRevenue'].values.reshape(-1, 1)\n",
    "\n",
    "#put stratify criteria of revenue/no_revenue into its own array, make sure to reshape this as well\n",
    "stratify_criteria_model = df_model['revenue_label'].values.reshape(-1, 1)\n",
    "\n",
    "print('\\nShape of X input variables is: ', X_model.shape, '\\nShape of y output variable is: ', y_model.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ???NEED TO SCALE/TRANSFORM THE DATA???? ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Shapes of the train-test data splits.\n",
      "\n",
      "X_model_train:  (676557, 622)\n",
      "X_model_test:  (225520, 622)\n",
      "y_model_train:  (676557, 1)\n",
      "y_model_test:  (225520, 1)\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Check that the train-test data split worked along stratify criteria.\n",
      "\n",
      "The df_model data percentages of revenue and no_revenue are:\n",
      "no_revenue    0.987242\n",
      "revenue       0.012758\n",
      "Name: revenue_label, dtype: float64\n",
      "\n",
      "The percentage of model_train data that has revenue is:  0.01275871803853925\n",
      "\n",
      "The percentage of model_test data that has revenue is:  0.012757183398368215\n"
     ]
    }
   ],
   "source": [
    "##### TRAIN-TEST-SPLIT #####\n",
    "\n",
    "### SPLIT THE MODEL DATA ###\n",
    "#split the model data (which is all of the Kaggle Training data) into the model's train/test subsets\n",
    "#(have to do this since Kaggle competition has its own test data, but those actual values are not provided, so can't\n",
    "#actually use that to test our models, just end up comparing our predictions on that test data with their actuals)\n",
    "#use a 75-25 split to start with train-test\n",
    "#also make sure to add stratify_criteria to make sure it is doing a 75-25 split on both website visits that led to \n",
    "#actual sales/revenue and those that did not\n",
    "X_model_train, X_model_test, y_model_train, y_model_test = train_test_split(X_model, y_model,\n",
    "                                                                            test_size=0.25,\n",
    "                                                                            stratify=stratify_criteria_model)\n",
    "#print sizes of the train/test data splits\n",
    "print('Check Shapes of the train-test data splits.\\n')\n",
    "print('X_model_train: ', X_model_train.shape)\n",
    "print('X_model_test: ', X_model_test.shape)\n",
    "print('y_model_train: ', y_model_train.shape)\n",
    "print('y_model_test: ', y_model_test.shape)\n",
    "\n",
    "\n",
    "### VERIFTY THE STRATEFIY COMMAND WORKED ###\n",
    "print('\\n--------------------------------------------------------------------')\n",
    "print('Check that the train-test data split worked along stratify criteria.\\n')\n",
    "\n",
    "# FIRST PRINT OUT TOTAL DF_MODEL PERCENTAGE OF DATA THAT HAS REVENUE #\n",
    "print('The df_model data percentages of revenue and no_revenue are:')\n",
    "#since this data from the df_model is in a series, we can just use pandas value counts\n",
    "print(df_model['revenue_label'].value_counts(normalize=True))\n",
    "\n",
    "# THEN CHECK THE TRAIN DATA #\n",
    "#the train data is now an array, so can't use value_counts, have to use np commands\n",
    "#filter the data to be only y_values that had revenue (rev>0) by using the np.where command\n",
    "#it creates a mask of booleans that you can use to filter your array based on whatever criteria you give it\n",
    "#take the length of this filtered array to figure out how many y_values actually had revenue\n",
    "y_model_train_revenue_count = len(y_model_train[np.where(y_model_train > 0)])\n",
    "#calculate the percentage of the y_values that have revenue by taking the revenue count/total count in that dataset \n",
    "#note: this percentage should equal the overall percentage of your data that has revenue if the stratify command is working properly\n",
    "y_model_train_revenue_percent = y_model_train_revenue_count/y_model_train.shape[0]\n",
    "print('\\nThe percentage of model_train data that has revenue is: ', y_model_train_revenue_percent)\n",
    "\n",
    "# THEN CHECK THE TEST DATA #\n",
    "#the test data is now an array, so can't use value_counts, have to use np commands\n",
    "#filter the data to be only y_values that had revenue (rev>0) by using the np.where command\n",
    "#it creates a mask of booleans that you can use to filter your array based on whatever criteria you give it\n",
    "#take the length of this filtered array to figure out how many y_values actually had revenue\n",
    "y_model_test_revenue_count = len(y_model_test[np.where(y_model_test > 0)])\n",
    "#calculate the percentage of the y_values that have revenue by taking the revenue count/total count in that dataset \n",
    "#note: this percentage should equal the overall percentage of your data that has revenue if the stratify command is working properly\n",
    "y_model_test_revenue_percent = y_model_test_revenue_count/y_model_test.shape[0]\n",
    "print('\\nThe percentage of model_test data that has revenue is: ', y_model_test_revenue_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Models v2\n",
    "### Version 2: Limited Input Variables, One Hot Encoding, No Scaling/Transforming of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initial Functions Used for Evaluation of Models\n",
    "These functions are being created to evaluate whether models are even identifying transactions correctly as revenue/no revenue (or even worse if it assigned negative revenue) because beyond the final revenue amount we want predicted, we also don't want predictions of revenue (or negative revenue) for someone that didn't buy anything and had 0 revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to define whether the outcome is revenue (when revenue_amt is greater than 0), \n",
    "#no_revenue (when revenue_amt is 0), and neg_revenue (when revenue_amt is less than 0)\n",
    "def revenue_norevenue_negrevenue(revenue_amt):\n",
    "    if revenue_amt > 0:\n",
    "        return 'revenue'\n",
    "    elif revenue_amt == 0:\n",
    "        return 'no_revenue'\n",
    "    elif revenue_amt < 0:\n",
    "        return 'neg_revenue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CREATE A FUNCTION THAT EVALUATES THE REVENUE OR NO_REVENUE ACCURACY ###\n",
    "#an important part of this model is to make sure that only people that actually performed a final transaction are \n",
    "#getting a revenue prediction\n",
    "#so calculate the percentages of each outcome in a confusion matrix using sklearn.metrics.confusion_matrix:\n",
    "# --True Positive: Revenue_actual & Revenue_predicted\n",
    "# --True Negative: No_Revenue_actual & No_Revenue_predicted\n",
    "# --False Negative: Revenue_actual & No_Revenue_predicted\n",
    "# --False Positive: No_Revenue_actual & Revenue_predicted\n",
    "\n",
    "#inputs of y_revenue_true, y_revenue_predicted are the actual revenue amount arrays,\n",
    "#we will convert to labels\n",
    "def evaluate_revenue_confusion_matrix(y_revenue_true, y_revenue_predicted):\n",
    "    df_revenue_eval = pd.DataFrame(data={'revenue_actual': y_revenue_true.reshape(-1),\n",
    "                       'revenue_prediction': y_revenue_predicted.reshape(-1)})\n",
    "    \n",
    "    df_revenue_eval['revenue_label_actual'] = df_revenue_eval.revenue_actual.map(revenue_norevenue_negrevenue)\n",
    "    \n",
    "    df_revenue_eval['revenue_label_prediction'] = df_revenue_eval.revenue_prediction.map(revenue_norevenue_negrevenue)\n",
    "    \n",
    "    print('Confusion Matrix of revenue/no_revenue/neg_revenue: \\n')\n",
    "    #use scikit learns confusion matrix (the diagonal indicates true hits, outside of that is the false hits)\n",
    "    print(confusion_matrix(df_revenue_eval.revenue_label_actual,\n",
    "                 df_revenue_eval.revenue_label_prediction,\n",
    "                 labels=['revenue', 'no_revenue', 'neg_revenue']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Linear Regression (Ordinary Least Squares) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### INSTANTIATE, FIT, and PREDICT THE MODEL ###\n",
    "\n",
    "#instantiate the LinearRegression model\n",
    "lin_reg_model = LinearRegression()\n",
    "\n",
    "#fit the training X, y data using the model\n",
    "lin_reg_model.fit(X_model_train, y_model_train)\n",
    "\n",
    "#make predictions using the model\n",
    "y_lin_reg_test_predictions = lin_reg_model.predict(X_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.5076884532984581e+26 \n",
      "R-squared: -56764922529.05086 \n",
      "Correlation: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael_suomi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    }
   ],
   "source": [
    "### EVALUATE THE MODEL USING MSE, R2, CORREL ###\n",
    "\n",
    "#MSE function syntax: mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)\n",
    "MSE_lin_reg = mean_squared_error(y_model_test, y_lin_reg_test_predictions)\n",
    "\n",
    "#R2 function syntax: r2_score(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)\n",
    "r2_lin_reg = r2_score(y_model_test, y_lin_reg_test_predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {} \\nR-squared: {} \\nCorrelation: {}\".format(MSE_lin_reg, r2_lin_reg, np.sqrt(r2_lin_reg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of revenue/no_revenue/neg_revenue: \n",
      "\n",
      "[[  2875      0      2]\n",
      " [106157      0 116486]\n",
      " [     0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_revenue_confusion_matrix(y_model_test, y_lin_reg_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Linear Lasso Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-f2c3f66986d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#fit the training X, y data using the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mlasso_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_model_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_model_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#make predictions using the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/michael_suomi/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, check_input)\u001b[0m\n\u001b[0;32m    759\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m                           \u001b[0mselection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m                           check_input=False)\n\u001b[0m\u001b[0;32m    762\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m             \u001b[0mdual_gaps_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/michael_suomi/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[1;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[0;32m    475\u001b[0m             model = cd_fast.enet_coordinate_descent(\n\u001b[0;32m    476\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m                 positive)\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             raise ValueError(\"Precompute should be one of True, False, \"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### INSTANTIATE, FIT, and PREDICT THE MODEL ###\n",
    "\n",
    "#instantiate the LinearRegression model\n",
    "lasso_model = Lasso(alpha=.01)\n",
    "\n",
    "#fit the training X, y data using the model\n",
    "lasso_model.fit(X_model_train, y_model_train)\n",
    "\n",
    "#make predictions using the model\n",
    "y_lasso_test_predictions = lasso_model.predict(X_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### EVALUATE THE MODEL USING MSE, R2, CORREL ###\n",
    "\n",
    "#MSE function syntax: mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)\n",
    "MSE_lasso = mean_squared_error(y_model_test, y_lasso_test_predictions)\n",
    "\n",
    "#R2 function syntax: r2_score(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)\n",
    "r2_lasso = r2_score(y_model_test, y_lasso_test_predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {} \\nR-squared: {} \\nCorrelation: {}\".format(MSE_lasso, r2_lasso, np.sqrt(r2_lasso)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_revenue_confusion_matrix(y_model_test, y_lasso_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Linear Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### INSTANTIATE, FIT, and PREDICT THE MODEL ###\n",
    "\n",
    "#instantiate the LinearRegression model\n",
    "ridge_model = Ridge(alpha=.01)\n",
    "\n",
    "#fit the training X, y data using the model\n",
    "ridge_model.fit(X_model_train, y_model_train)\n",
    "\n",
    "#make predictions using the model\n",
    "y_ridge_test_predictions = ridge_model.predict(X_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2582204260843450.5 \n",
      "R-squared: 0.027792349919062653 \n",
      "Correlation: 0.16671037735864752\n"
     ]
    }
   ],
   "source": [
    "### EVALUATE THE MODEL USING MSE, R2, CORREL ###\n",
    "\n",
    "#MSE function syntax: mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)\n",
    "MSE_ridge = mean_squared_error(y_model_test, y_ridge_test_predictions)\n",
    "\n",
    "#R2 function syntax: r2_score(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)\n",
    "r2_ridge = r2_score(y_model_test, y_ridge_test_predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {} \\nR-squared: {} \\nCorrelation: {}\".format(MSE_ridge, r2_ridge, np.sqrt(r2_ridge)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of revenue/no_revenue/neg_revenue: \n",
      "\n",
      "[[  2875      0      2]\n",
      " [106164      0 116479]\n",
      " [     0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_revenue_confusion_matrix(y_model_test, y_ridge_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Linear Elastic Net Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael_suomi/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "### INSTANTIATE, FIT, and PREDICT THE MODEL ###\n",
    "\n",
    "#instantiate the LinearRegression model\n",
    "elastic_net_model = ElasticNet(alpha=.01)\n",
    "\n",
    "#fit the training X, y data using the model\n",
    "elastic_net_model.fit(X_model_train, y_model_train)\n",
    "\n",
    "#make predictions using the model\n",
    "y_elastic_net_test_predictions = elastic_net_model.predict(X_model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2581631994467428.5 \n",
      "R-squared: 0.028007809926270166 \n",
      "Correlation: 0.16735534029803223\n"
     ]
    }
   ],
   "source": [
    "### EVALUATE THE MODEL USING MSE, R2, CORREL ###\n",
    "\n",
    "#MSE function syntax: mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)\n",
    "MSE_elastic_net = mean_squared_error(y_model_test, y_elastic_net_test_predictions)\n",
    "\n",
    "#R2 function syntax: r2_score(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)\n",
    "r2_elastic_net = r2_score(y_model_test, y_elastic_net_test_predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {} \\nR-squared: {} \\nCorrelation: {}\".format(MSE_elastic_net, r2_elastic_net, np.sqrt(r2_elastic_net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of revenue/no_revenue/neg_revenue: \n",
      "\n",
      "[[  2875      0      2]\n",
      " [106444      0 116199]\n",
      " [     0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_revenue_confusion_matrix(y_model_test, y_elastic_net_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
