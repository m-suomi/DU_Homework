{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars\n",
    "\n",
    "## Step 1 - Scraping\n",
    "\n",
    "Complete your initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "\n",
    "* Create a Jupyter Notebook file called `mission_to_mars.ipynb` and use this to complete all of your scraping and analysis tasks. The following outlines what you need to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### NASA Mars News\n",
    "\n",
    "* Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "news_title = \"NASA's Next Mars Mission to Investigate Interior of Red Planet\"\n",
    "\n",
    "news_p = \"Preparation of NASA's next spacecraft to Mars, InSight, has ramped up this summer, on course for launch next May from Vandenberg Air Force Base in central California -- the first interplanetary launch in history from America's West Coast.\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Mars News Data by finding the Internal API Request, Using that URL, and then Extracting Data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_json(web_url):\n",
    "#     response_json = requests.get(web_url).json()\n",
    "#     return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #the Mars webpage calls another API to get the majority of its body info,\n",
    "# #so the page source doesn't have the major content in its html - go to Network>XHR on the Inspect details\n",
    "# #to find the webpage that returns the main information (this one returns as json to just parse out that)\n",
    "# mars_news_json = get_json('https://mars.nasa.gov/api/v1/news_items/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mars_news_title = mars_news_json.get('items')[0].get('title')\n",
    "# print('Most Recent News Title: ', mars_news_title)\n",
    "\n",
    "# mars_news_descriptor = mars_news_json.get('items')[0].get('description')\n",
    "# print('Most Recent News Descriptor: ', mars_news_descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Mars News  Data by Using Selenium (so can extract all information processed by Javascript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_selenium_driver():\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--window-size=1420,1080')\n",
    "    #chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\micha\\Google Drive\\Data Science\\chromedriver.exe', \n",
    "        chrome_options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_selenium(web_url):\n",
    "    driver = instantiate_selenium_driver()\n",
    "\n",
    "    driver.get(web_url)\n",
    "    data_page = driver.page_source\n",
    "    \n",
    "    soup = BeautifulSoup(data_page, 'html.parser')\n",
    "    driver.quit()\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recent News Title:  Six Things About Opportunity's Recovery Efforts\n",
      "Most Recent News Descriptor:  The global dust storm on Mars could soon let in enough sunlight for the Opportunity rover to recharge.\n"
     ]
    }
   ],
   "source": [
    "mars_news_soup2 = get_soup_selenium('https://mars.nasa.gov/news/')\n",
    "\n",
    "#find just latest article title and teaser text - so use find to get first item\n",
    "mars_news_title2 = mars_news_soup2.find('div', {'class': 'content_title'}).text\n",
    "print('Most Recent News Title: ', mars_news_title2)\n",
    "mars_news_descriptor2 = mars_news_soup2.find('div', {'class': 'article_teaser_body'}).text\n",
    "print('Most Recent News Descriptor: ',mars_news_descriptor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "\n",
    "* Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "\n",
    "* Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "* Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "* Make sure to save a complete url string for this image.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16225_hires.jpg'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full resolution jpg image is at:  https://photojournal.jpl.nasa.gov/jpeg/PIA14712.jpg\n"
     ]
    }
   ],
   "source": [
    "driver = instantiate_selenium_driver()\n",
    "driver.get('https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars')\n",
    "\n",
    "#find and click on the full_image link of the header\n",
    "full_image_button = driver.find_element_by_id('full_image')\n",
    "full_image_button.click()\n",
    "\n",
    "#the picture that shows up is in a carousel of previous feature images\n",
    "#this picture is still a medium size (or large size depending on your browser,\n",
    "#but not full size).  go to 'more info' button to find details of the image\n",
    "time.sleep(1) #takes a little bit for this page to load, button won't show up if script runs instantly\n",
    "more_info_button = driver.find_element_by_link_text('more info')\n",
    "# more_info_button = driver.find_element_by_partial_link_text('info')\n",
    "more_info_button.click()\n",
    "\n",
    "#get soup of current more info page\n",
    "more_info_page = driver.page_source\n",
    "image_more_info_soup = BeautifulSoup(more_info_page, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "#jpeg link is the second li in download_tiff class (first is download tiff if want that one)\n",
    "full_res_jpg_url = image_more_info_soup.find_all('div', {'class':'download_tiff'})\\\n",
    "                                                [1].a.attrs['href']\n",
    "full_res_jpg_url = 'https:' + full_res_jpg_url\n",
    "print('The full resolution jpg image is at: ', full_res_jpg_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather\n",
    "\n",
    "* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "mars_weather = 'Sol 1801 (Aug 30, 2017), Sunny, high -21C/-5F, low -80C/-112F, pressure at 8.82 hPa, daylight 06:09-17:55'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_feed_soup = get_soup_selenium('https://twitter.com/marswxreport?lang=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest weather on Mars is:  Sol 2142 (2018-08-15), high -10C/14F, low -71C/-95F, pressure at 8.65 hPa, daylight 05:28-17:41\n"
     ]
    }
   ],
   "source": [
    "#get all the tweet texts from the page\n",
    "#find the first one in the list that has weather info (since they post some \n",
    "#tweets that are not a normal weather report) by selecting a text that includes\n",
    "#high, low, pressure, and daylight\n",
    "tweets_text = [tweet_paragraph.text for tweet_paragraph in\n",
    "               twitter_feed_soup.find_all('p', {'class':'tweet-text'})]\n",
    "for tweet_text in tweets_text:\n",
    "    if all(word in tweet_text for word in ['high', 'low', 'pressure', 'daylight']):\n",
    "        latest_mars_weather = tweet_text\n",
    "        break\n",
    "print('The latest weather on Mars is: ', latest_mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "\n",
    "* Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "* Use Pandas to convert the data to a HTML table string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equatorial Diameter:</td>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polar Diameter:</td>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orbit Distance:</td>\n",
       "      <td>227,943,824 km (1.52 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orbit Period:</td>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Surface Temperature:</td>\n",
       "      <td>-153 to 20 째C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>First Record:</td>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recorded By:</td>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                              1\n",
       "0  Equatorial Diameter:                       6,792 km\n",
       "1       Polar Diameter:                       6,752 km\n",
       "2                 Mass:  6.42 x 10^23 kg (10.7% Earth)\n",
       "3                Moons:            2 (Phobos & Deimos)\n",
       "4       Orbit Distance:       227,943,824 km (1.52 AU)\n",
       "5         Orbit Period:           687 days (1.9 years)\n",
       "6  Surface Temperature:                  -153 to 20 째C\n",
       "7         First Record:              2nd millennium BC\n",
       "8          Recorded By:           Egyptian astronomers"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mars facts page doesn't load with javascript so can directly read tables into pandas \n",
    "#without using selenium, and only one table on the page\n",
    "df_mars_facts = pd.read_html('http://space-facts.com/mars/')[0]\n",
    "print(df_mars_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Html Code for Table: \n",
      "\n",
      " <table border=\"1\" class=\"dataframe\">\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>Equatorial Diameter:</td>\n",
      "      <td>6,792 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Polar Diameter:</td>\n",
      "      <td>6,752 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Mass:</td>\n",
      "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Moons:</td>\n",
      "      <td>2 (Phobos &amp; Deimos)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Orbit Distance:</td>\n",
      "      <td>227,943,824 km (1.52 AU)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Orbit Period:</td>\n",
      "      <td>687 days (1.9 years)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Surface Temperature:</td>\n",
      "      <td>-153 to 20 째C</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>First Record:</td>\n",
      "      <td>2nd millennium BC</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Recorded By:</td>\n",
      "      <td>Egyptian astronomers</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "mars_facts_html_table = df_mars_facts.to_html(header=False, index=False)\n",
    "print('Html Code for Table: \\n\\n', mars_facts_html_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Mars Hemispheres\n",
    "\n",
    "* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The USGS page doesn't load with javascript, so can just use response and beautiful soup to find href links and go to each one instead of using selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the soup from the main mars hemispheres page\n",
    "USGS_response = requests.get('https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars')\n",
    "USGS_soup = BeautifulSoup(USGS_response.text, 'html.parser')\n",
    "\n",
    "#find all of the relative links from the hemispheres - under a tags of class: product-item\n",
    "#and add on main url to front of https://astrogeology.usgs.gov\n",
    "USGS_hem_links = ['https://astrogeology.usgs.gov' + a['href'] for a\n",
    "                    in USGS_soup.find_all('a', {'class': 'product-item'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, {'title': 'Schiaparelli Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}, {'title': 'Syrtis Major Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}, {'title': 'Valles Marineris Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "#run a for loop to go through each link from the main page to visit each hemisphere page\n",
    "#and extract required data and store in list as dictionary for each hemisphere\n",
    "hemisphere_image_urls = []\n",
    "for hem_link in USGS_hem_links:\n",
    "    #get soup from hemisphere page\n",
    "    hem_soup = BeautifulSoup(requests.get(hem_link).text, 'html.parser')\n",
    "\n",
    "    #get name of hemisphere - note: all the hemisphere titles have extra string of Enhanced\n",
    "    #at the end, so remove that for true title\n",
    "    hem_title = hem_soup.find('h2', {'class':'title'}).text.replace(' Enhanced', '')\n",
    "\n",
    "    #for imageurl: go to downloads div, and within that find the href that has text of Sample\n",
    "    #(Original will only give a link that downloads, but we will want to show the img on our webpage)\n",
    "    hem_img_url = hem_soup.find('div', {'class': 'downloads'}).find('a', text='Sample')['href']\n",
    "\n",
    "    #append dictionary to list\n",
    "    hemisphere_image_urls.append(dict([('title', hem_title), ('img_url', hem_img_url)]))\n",
    "\n",
    "print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Store to MongoDB\n",
    "\n",
    "- convert everything to dictionary\n",
    "- store that data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect all mars scraped data - include an _id for mongo that is the timestamp\n",
    "#of when collected all the info\n",
    "mars_scraped_data = {\n",
    "    '_id': str(datetime.datetime.now()).split('.')[0],\n",
    "    'mars_news': {'mars_news_title': mars_news_title2,\n",
    "                  'mars_news_descripter': mars_news_descriptor2},\n",
    "    'mars_img_url': full_res_jpg_url,\n",
    "    'mars_weather': latest_mars_weather,\n",
    "    'mars_facts_html_table': mars_facts_html_table,\n",
    "    'mars_hemisphere_image_urls': hemisphere_image_urls\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup Mongo Client for mars database and a collection called mars_news\n",
    "client = MongoClient('localhost', 27017) #local mongo client\n",
    "db = client.mars\n",
    "collection = db.mars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x1f776043fc8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert the mars news data dictionary\n",
    "collection.insert_one(mars_scraped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Create Flask Application \n",
    "- do this in regular.py script\n",
    "- but first try code that calls info from mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Mongo client is still setup from when stored the mars dictionary to Mongo\n",
    "# client = MongoClient('localhost', 27017) #local mongo client\n",
    "# db = client.mars\n",
    "# collection = db.mars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-08-18 08:20:54', '2018-08-18 12:36:47', '2018-08-19 05:39:40']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #look at all documents in the collection\n",
    "# docs = [d for d in collection.find()]\n",
    "# docs\n",
    "\n",
    "#look at all ids of the documents in the collection\n",
    "doc_ids = [d.get('_id') for d in collection.find()]\n",
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '2018-08-19 05:39:40',\n",
       " 'mars_facts_html_table': '<table border=\"1\" class=\"dataframe\">\\n  <tbody>\\n    <tr>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 째C</td>\\n    </tr>\\n    <tr>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>',\n",
       " 'mars_hemisphere_image_urls': [{'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif',\n",
       "   'title': 'Cerberus Hemisphere'},\n",
       "  {'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif',\n",
       "   'title': 'Schiaparelli Hemisphere'},\n",
       "  {'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif',\n",
       "   'title': 'Syrtis Major Hemisphere'},\n",
       "  {'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif',\n",
       "   'title': 'Valles Marineris Hemisphere'}],\n",
       " 'mars_img_url': 'https://photojournal.jpl.nasa.gov/jpeg/PIA18640.jpg',\n",
       " 'mars_news': {'mars_news_descripter': 'The global dust storm on Mars could soon let in enough sunlight for the Opportunity rover to recharge.',\n",
       "  'mars_news_title': \"Six Things About Opportunity's Recovery Efforts\"},\n",
       " 'mars_weather': 'Sol 2142 (2018-08-15), high -10C/14F, low -71C/-95F, pressure at 8.65 hPa, daylight 05:28-17:41'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instead of overwriting all the dataset (like the homework instructions foolishly\n",
    "# tell us to) we will just access the latest item from the collection when calling\n",
    "# the data, so can do this by sorting descending (-1) on _id (which has the timestamp\n",
    "# string saved) and getting the first\n",
    "latest_mars_data = collection.find_one(sort = [('_id', -1)])\n",
    "latest_mars_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
